\section{Desarrollo}

\subsection{Descripción del \textit{dataset}}

\noindent
El \textit{dataset} con el que estamos trabajando posee tres carpetas: una para los datos de \textit{train}, otra para los datos de \textit{test} y, por último, una 
tercera para los datos de \textit{validation}. En estas carpetas se encuentran las imágenes y un documento en formato \texttt{.csv} llamado \texttt{annotations}, que 
contiene la información de las imágenes. La siguiente tabla describe los atributos del documento


\quad

\begin{figure}[H]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        \textbf{Atributo} & \textbf{Tipo de dato} & \textbf{Descripción del atributo} \\ \hline
        filename & string & Nombre de la imagen \\ \hline
        width & int & Anchura de la imagen \\ \hline
        height & int & Altura de la imagen \\ \hline
        class & string & Clase de la imagen \\ \hline
        xmin & \multirow{4}{*}{int} & \multirow{4}{*}{\shortstack[l]{Coordenadas de la clase\\ \text{ }detectada en la imagen}} \\ 
        \cline{1-1}
        ymin &  &  \\ 
        \cline{1-1}
        xmax &  &  \\ 
        \cline{1-1}
        ymax &  &  \\ 
        \hline
    \end{tabular}
    \caption{Atributos del \textit{dataset}}
\end{figure}

\noindent
En cuanto a la distribución de las imágenes, tenemos 448 imágenes de \textit{train}, 63 imágenes de \textit{test} y 127 imágenes de \textit{validation}. Por tanto, 
estamos ante un \textit{dataset} bastante limitado, teniendo en cuenta que estamos trabajando con imágenes y que nuestro objetivo es clasificarlas. Esto abre la puerta 
al uso de técnicas de \textit{data augmentation}, así como al empleo de arquitecturas de red preentrenadas para aplicar \textit{transfer learning}. 

\quad

\noindent
Además, existe un notable desbalanceo en la cantidad de imágenes representativas de cada clase, lo cual refuerza la necesidad de implementar una estrategia adecuada de 
\textit{data augmentation} para mejorar la diversidad del conjunto de datos y mitigar los efectos negativos del desequilibrio en el entrenamiento del modelo.

\subsection{Organización del \textit{dataset}}

\noindent
Para facilitar el trabajo con el \textit{dataset}, hemos automatizado su descarga, extracción y organización en carpetas según la clase dominante de
cada imagen. Para ello, subimos el archivo \texttt{.zip} a \href{https://drive.google.com/uc?id=1iGBv-VT5mm1RiouD-U2qWcU3BYqp2OwE}{Google Drive} y 
desarrollamos un código para descargarlo y descomprimirlo utilizando la libraría gdown. Este contiene imágenes de 7 clases diferentes agrupadas en carpetas train, test y valid (validation).  

\quad  

\noindent
A continuación se procede a etiquetar el dataset, aunque el conjunto de datos sugiere una sobrepoblación de peces en las imágenes, que clase de animal marino predomina en cada imagen se determinará a partir del área y número de veces que aparece una clase.

\noindent
Se define el siguiente criterio:
\begin{equation}
    \text{Dominant Class} = \arg\max_{c \in \mathcal{C}} \left( \text{area}_c \cdot \text{count}_c \right)
\end{equation}


\noindent
Para una imagen la clase predominante será aquella cuyo producto área por número de veces que aparece sea mayor.La información que permite este cálculo se encuentra en los archivos csv de anotación disponibles en cada una de las carpetas train, test y valid. 
Estos archivos contienen las asociaciones entre entidad e imagen, y en particular contienen los bounding boxes de los animales identificados en cada imagen. 

\quad  

\noindent
Para obtener el conteo de una clase en cada imagen se agrupan las anotaciones por imagen y clase, y se aplica el método .size() que nos devuelve el tamaño de las agrupaciones.

\quad  

\noindent
Para obtener el área de una clase primero se calcula para cada entidad y posteriormente se agrupa por imagen y clase para aplicar el método .sum() que nos devuelve la suma de áreas de una clase para cada imagen.

\quad  

\noindent
Como consideraciones a futuro se podría tener en cuenta si existe superposición de bounding boxes y en su caso adaptar el cálculo de área, para esta práctica por no especificarse un criterio y ser un enfoque simple no se tienen en cuenta las intersecciones.

\quad  

\noindent
Se tiene entonces pares (imagen, clase), para guardar este cálculo en forma de organización del repositorio, se crean en los sets de train, test y valid subcarpetas con nombres las etiquetas y se mueven las imágenes a sus respectivas carpetas. El algoritmo que define esta organización pasa por obtener los nuevos paths utilizando los nombres de imágenes y añadiendo las etiquetas correspondientes. El módulo shutil de Python nos permite mover los archivos y con un bloque try-except se evita que se produzcan errores si alguno de los archivos no se encuentra (esperable si ya se han movido a las subcarpetas).

\subsection{Preprocesamiento}

\noindent
Una vez el dataset se encuentra organizado en subcarpetas de clase dominante (dentro de cada carpeta \textit{train}, \textit{test} y \textit{validation}), se preprocesan las imágenes definiendo una serie de pasos que permiten obtener entradas adecuadas para nuestros modelos.

Para definir estos pasos a modo de pipeline se utiliza un tipo de dato nativo de tensorflow, el tensorflow.data.Dataset, este tipo de objeto es muy conveniente porque permite definir de manera sencilla y secuencial los pasos para transformar los datos en inputs adecuados para modelos de aprendizaje construidos con tensorflow. Se trata de un objeto por el que pasan y se pueden hacer operaciones con tensores en un formato eficiente.

Como entradas al pipeline se tienen los paths a las imágenes en los cuales están las etiquetas correspondientes (las imágenes han sido organizadas previamente en sus subcarpetas de clase). 

Utilizando el objeto Dataset del módulo data de tensorflow se almacena tensores de paths y son estas cadenas binarias las que se convierten en pares (imagen, etiqueta) tras una serie de pasos:

\begin{itemize}
    \item Se obtienen las etiquetas en formato one-hot encoded: extrayendo del path el nombre de la etiqueta y mapeandolo a un entero utilizando una tabla hash se obtiene el entero asociado a la clase, que finalmente se convierte a formato one-hot. En este punto el pipeline devuelve pares path a la imagen y etiqueta en formato one-hot.

    \item Se obtienen las imágenes: utilizando las funciones io de tensorflow.

    \item Redimensionado de las imágenes: Las imágenes anteriores son de tamaño variable, mientras que los modelos que se van a utilizar esperan datos para entrenar con las mismas dimensiones, primero se añade padding para conseguir que todas las imágenes sean 1024x1024 y después se redimensionan para utilizar un tamaño 64x64 como entrada en el caso Pre-train y 224x224 en el caso Fine-tuning. 

    \item Media 0 y desviación 1: Una vez se tienen las imágenes en un tamaño adecuado se escalan sus características, esto es, los valores de los pixels se escalan para que tengan media 0 y desviación 1. Esto se realiza para conseguir una convergencia más rápida.

\end{itemize}

\subsection{\textit{Data Augmentation}}

Tras el preprocesamiento de las imágenes, con la finalidad de obtener mayor diversidad en el conjunto de datos se han realizado pequeñas transformaciones en las imágenes, que pueden ayudar a que el modelo  sobreentrene menos, mejorando su capacidad de generalización.

Para ello, se han aplicado inversiones horizontales, así como rotaciones, zooms y recortes, todo ello se ha llevado a cabo de manera pseudoaleatoria.

\subsection{\textit{Pre-Train}}

En esta sección se han diseñado 3 modelos que cumplan las especificaciones pedidas:
\begin{itemize}
    \item Al menos 3 capas convolucionales.
    \item ReLU como función de activación
    \item softmax para la salida de la última capa.
    \item Uso de la optimización RMSprop.
    \item categorical crossentropy como función de pérdida
    \item RMSprop para minimizar la función de pérdida
\end{itemize}


% Para repetir el proceso de definicion de arquitecturas en un bucle para distintos hiperparametros se define una funcion build_model que recibe como argumentos tamaños de kernel, tamaños de pooling, numero de capas y tasa de aprendizaje para ejecutar el proceso de entrenamiento.

Se pide que utilizar 3 configuraciones de tamaños de kernel, tamaños de pooling, número de capas y tasa de aprendizaje para ejecutar el proceso de entrenamiento.

Se han elegido tres tasas de aprendizaje variable dependiente de un parámetro paciencia que reduce el learning rate si no mejora el entrenamiento, de forma que se refine el mínimo de la pérdida cuando la red no mejora.

Pasos realizados:

\begin{itemize}
    \item Definir callbacks: se define el EarlyStopping y el ReduceLROnPlateau. Lo que permite detener el entrenamiento cuando la red no mejora sobre datos de validación y por otro lado obtenemos un learning rate variable dependiente del parámetro paciencia.
    \item Definir el modelo: se definen sus capas a partir de los parámetros elegidos.
    \item Compilar el modelo: se definen las funciones de perdida y optimizador.
\end{itemize}

Finalmente con un bucle se obtienen los resultados del entrenamiento y se elige el mejor modelo.

\subsection{\textit{Fine-Tuning}}
Para el caso Fine-Tuning solo se utilizan 3 configuraciones de tasas de learning rate variables
y la arquitectura del modelo se basa en un modelo preentrenado, en nuestro caso y tras varias pruebas hemos elegido el modelo MobileNetV3Large.

De nuevo con un bucle se obtienen los resultados del entrenamiento y se elige el mejor modelo. 


