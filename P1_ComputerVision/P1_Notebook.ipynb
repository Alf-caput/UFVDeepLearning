{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practica 1 - Computer Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data zipfile already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gdown\n",
    "\n",
    "# Crear el directorio de datos si no existe\n",
    "data_dir = \"data\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "# URL de Google Drive en formato correcto para gdown\n",
    "url = \"https://drive.google.com/uc?id=1iGBv-VT5mm1RiouD-U2qWcU3BYqp2OwE\"\n",
    "zip_filename = \"practica_1_dataset.zip\"\n",
    "zip_path = os.path.join(data_dir, zip_filename)\n",
    "\n",
    "# Descargar el archivo\n",
    "if not os.path.exists(zip_path):\n",
    "    gdown.download(url, zip_path, quiet=False)\n",
    "else:\n",
    "    print(\"Data zipfile already exists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, train and valid folders already exist\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "data_dir = \"data\"\n",
    "zip_filename = \"practica_1_dataset.zip\"\n",
    "zip_path = os.path.join(data_dir, zip_filename)\n",
    "subfolders = [\"test\", \"train\", \"valid\"]\n",
    "full_paths = [os.path.join(data_dir, folder) for folder in subfolders]\n",
    "\n",
    "if not all(os.path.isdir(path) for path in full_paths):\n",
    "    with ZipFile(zip_path, 'r') as zf:\n",
    "        with ThreadPoolExecutor() as exe:\n",
    "            for file in zf.namelist():\n",
    "                if not file.startswith(\"__MACOSX\"):\n",
    "                    exe.submit(zf.extract, file, path=data_dir)\n",
    "else:\n",
    "    print(\"test, train and valid folders already exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total image files in test: 63\n",
      "Filenames shape: TensorSpec(shape=(), dtype=tf.string, name=None)\n",
      "Total image files in train: 448\n",
      "Filenames shape: TensorSpec(shape=(), dtype=tf.string, name=None)\n",
      "Total image files in valid: 127\n",
      "Filenames shape: TensorSpec(shape=(), dtype=tf.string, name=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'data/valid/IMG_2277_jpeg_jpg.rf.86c72d6192da48d941ffa957f4780665.jpg'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "for folder in subfolders:\n",
    "    folder_path = os.path.join(data_dir, folder)\n",
    "    ds_files = tf.data.Dataset.list_files(folder_path + \"/*.jpg\", shuffle=False)\n",
    "    print(f\"Total image files in {folder}: {len(ds_files)}\")\n",
    "    print(\"Filenames shape:\", ds_files.element_spec)\n",
    "\n",
    "example = next(ds_files.take(1).as_numpy_iterator())\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_class.shape = (83,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "filename                                                   class  \n",
       "IMG_2289_jpeg_jpg.rf.fe2a7a149e7b11f2313f5a7b30386e85.jpg  puffin      1\n",
       "IMG_2301_jpeg_jpg.rf.2c19ae5efbd1f8611b5578125f001695.jpg  penguin    23\n",
       "IMG_2319_jpeg_jpg.rf.6e20bf97d17b74a8948aa48776c40454.jpg  penguin     8\n",
       "IMG_2347_jpeg_jpg.rf.7c71ac4b9301eb358cd4a832844dedcb.jpg  penguin     2\n",
       "IMG_2354_jpeg_jpg.rf.396e872c7fb0a95e911806986995ee7a.jpg  penguin     5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/test/annotations.csv\")\n",
    "count_class = df.groupby([\"filename\", \"class\"]).size()\n",
    "print(f\"{count_class.shape = }\")\n",
    "count_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum_area.shape = (83,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "filename                                                   class  \n",
       "IMG_2289_jpeg_jpg.rf.fe2a7a149e7b11f2313f5a7b30386e85.jpg  puffin      94864\n",
       "IMG_2301_jpeg_jpg.rf.2c19ae5efbd1f8611b5578125f001695.jpg  penguin     32549\n",
       "IMG_2319_jpeg_jpg.rf.6e20bf97d17b74a8948aa48776c40454.jpg  penguin     29583\n",
       "IMG_2347_jpeg_jpg.rf.7c71ac4b9301eb358cd4a832844dedcb.jpg  penguin    250311\n",
       "IMG_2354_jpeg_jpg.rf.396e872c7fb0a95e911806986995ee7a.jpg  penguin     14881\n",
       "Name: area, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"area\"] = (df[\"xmax\"] - df[\"xmin\"]) * (df[\"ymax\"] - df[\"ymin\"])\n",
    "sum_area = df.groupby([\"filename\", \"class\"])[\"area\"].sum()\n",
    "print(f\"{sum_area.shape = }\")\n",
    "sum_area.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score.shape = (83, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>class</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG_2289_jpeg_jpg.rf.fe2a7a149e7b11f2313f5a7b3...</td>\n",
       "      <td>puffin</td>\n",
       "      <td>94864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG_2301_jpeg_jpg.rf.2c19ae5efbd1f8611b5578125...</td>\n",
       "      <td>penguin</td>\n",
       "      <td>748627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG_2319_jpeg_jpg.rf.6e20bf97d17b74a8948aa4877...</td>\n",
       "      <td>penguin</td>\n",
       "      <td>236664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG_2347_jpeg_jpg.rf.7c71ac4b9301eb358cd4a8328...</td>\n",
       "      <td>penguin</td>\n",
       "      <td>500622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG_2354_jpeg_jpg.rf.396e872c7fb0a95e911806986...</td>\n",
       "      <td>penguin</td>\n",
       "      <td>74405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename    class   score\n",
       "0  IMG_2289_jpeg_jpg.rf.fe2a7a149e7b11f2313f5a7b3...   puffin   94864\n",
       "1  IMG_2301_jpeg_jpg.rf.2c19ae5efbd1f8611b5578125...  penguin  748627\n",
       "2  IMG_2319_jpeg_jpg.rf.6e20bf97d17b74a8948aa4877...  penguin  236664\n",
       "3  IMG_2347_jpeg_jpg.rf.7c71ac4b9301eb358cd4a8328...  penguin  500622\n",
       "4  IMG_2354_jpeg_jpg.rf.396e872c7fb0a95e911806986...  penguin   74405"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = pd.Series(sum_area * count_class, name=\"score\").reset_index()\n",
    "print(f\"{score.shape = }\")\n",
    "score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_labels.shape = (63, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IMG_2289_jpeg_jpg.rf.fe2a7a149e7b11f2313f5a7b30386e85.jpg</th>\n",
       "      <td>puffin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMG_2301_jpeg_jpg.rf.2c19ae5efbd1f8611b5578125f001695.jpg</th>\n",
       "      <td>penguin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMG_2319_jpeg_jpg.rf.6e20bf97d17b74a8948aa48776c40454.jpg</th>\n",
       "      <td>penguin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMG_2347_jpeg_jpg.rf.7c71ac4b9301eb358cd4a832844dedcb.jpg</th>\n",
       "      <td>penguin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMG_2354_jpeg_jpg.rf.396e872c7fb0a95e911806986995ee7a.jpg</th>\n",
       "      <td>penguin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      class\n",
       "filename                                                   \n",
       "IMG_2289_jpeg_jpg.rf.fe2a7a149e7b11f2313f5a7b30...   puffin\n",
       "IMG_2301_jpeg_jpg.rf.2c19ae5efbd1f8611b5578125f...  penguin\n",
       "IMG_2319_jpeg_jpg.rf.6e20bf97d17b74a8948aa48776...  penguin\n",
       "IMG_2347_jpeg_jpg.rf.7c71ac4b9301eb358cd4a83284...  penguin\n",
       "IMG_2354_jpeg_jpg.rf.396e872c7fb0a95e9118069869...  penguin"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = score.groupby(\"filename\").max().drop(\"score\", axis=1)\n",
    "print(f\"{df_labels.shape = }\")\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1024, 1024, 3])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "ds_files = tf.data.Dataset.list_files(\"data/test/\" + '*.jpg', shuffle=False)\n",
    "df = pd.read_csv(\"data/test/annotations.csv\")\n",
    "df[\"class\"] = pd.Categorical(df[\"class\"])\n",
    "def get_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    target_size = 1024\n",
    "    image_padded = tf.image.resize_with_pad(image, target_size, target_size)\n",
    "    return image_padded\n",
    "\n",
    "ds_iter = ds_files.take(1).as_numpy_iterator()\n",
    "example = next(ds_iter)\n",
    "image = get_image(example)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "ds_files = tf.data.Dataset.list_files(\"data/test/\" + '*.jpg', shuffle=False)\n",
    "df = pd.read_csv(\"data/test/annotations.csv\")\n",
    "df[\"class\"] = pd.Categorical(df[\"class\"])\n",
    "\n",
    "def get_label(image_path, df):\n",
    "    # parts = tf.strings.split(image_path, os.path.sep)\n",
    "    # filename = parts[-1].numpy().decode(\"utf-8\")\n",
    "    _, filename = os.path.split(image_path.decode(\"utf-8\"))\n",
    "    return filename\n",
    "    image_annotations = df[df[\"filename\"] == filename].copy(deep=True)\n",
    "    image_annotations[\"area\"] = (image_annotations[\"xmax\"] - image_annotations[\"xmin\"]) * (image_annotations[\"ymax\"] - image_annotations[\"ymin\"]).values\n",
    "    class_area = image_annotations.groupby([\"filename\", \"class\"], observed=True)[\"area\"].sum()\n",
    "    return class_area[class_area == class_area.max()].reset_index(\"class\")[\"class\"].cat.codes.values\n",
    "\n",
    "ds_iter = ds_files.take(1).as_numpy_iterator()\n",
    "example = next(ds_iter)\n",
    "label = get_label(example, df)\n",
    "label[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 63\n",
      "Image shape: (TensorSpec(shape=(1024, 1024, 3), dtype=tf.float32, name=None), TensorSpec(shape=<unknown>, dtype=tf.int64, name=None))\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "ds_files = tf.data.Dataset.list_files(\"data/test/\" + '*.jpg', shuffle=False)\n",
    "df = pd.read_csv(\"data/test/annotations.csv\")\n",
    "df[\"class\"] = pd.Categorical(df[\"class\"])\n",
    "ds_images = (\n",
    "    ds_files\n",
    "    .shuffle(len(ds_files))\n",
    "    .cache()\n",
    "    .map(lambda x: (get_image(x), get_label(x, df)), num_parallel_calls=AUTOTUNE)\n",
    ")\n",
    "\n",
    "print(\"Total images:\", len(ds_images))\n",
    "print(\"Image shape:\", ds_images.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "def get_label(image_path, df):\n",
    "    def _lookup_label(image_path):\n",
    "        image_path = image_path.decode(\"utf-8\")  # Convert Tensor to string\n",
    "        parts = image_path.split(os.path.sep)\n",
    "        filename = parts[-1]\n",
    "\n",
    "        # Process DataFrame\n",
    "        image_annotations = df[df[\"filename\"] == filename].copy(deep=True)\n",
    "        image_annotations[\"area\"] = (image_annotations[\"xmax\"] - image_annotations[\"xmin\"]) * (image_annotations[\"ymax\"] - image_annotations[\"ymin\"]).values\n",
    "        class_area = image_annotations.groupby([\"filename\", \"class\"], observed=True)[\"area\"].sum()\n",
    "        \n",
    "        # Return the class with max area\n",
    "        return class_area[class_area == class_area.max()].reset_index(\"class\")[\"class\"].cat.codes.values\n",
    "\n",
    "    # Wrap the function inside `tf.py_function`\n",
    "    label = tf.py_function(func=_lookup_label, inp=[image_path], Tout=tf.int64)\n",
    "    return label\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "ds_files = tf.data.Dataset.list_files(\"data/test/\" + '*.jpg', shuffle=False)\n",
    "df = pd.read_csv(\"data/test/annotations.csv\")\n",
    "df[\"class\"] = pd.Categorical(df[\"class\"])\n",
    "\n",
    "ds_images = (\n",
    "    ds_files\n",
    "    .shuffle(len(ds_files))\n",
    "    .cache()\n",
    "    .map(lambda x: (get_image(x), get_label(x, df)), num_parallel_calls=AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 17:16:07.484640: W tensorflow/core/framework/op_kernel.cc:1844] UNKNOWN: AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/tmp/__autograph_generated_filewhy2r9h7.py\", line 16, in _lookup_label\n",
      "    image_path = ag__.converted_call(ag__.ld(image_path).decode, ('utf-8',), None, fscope_1)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor.py\", line 260, in __getattr__\n",
      "    self.__getattribute__(name)\n",
      "\n",
      "AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "\n",
      "\n",
      "2025-03-28 17:16:07.488141: W tensorflow/core/framework/op_kernel.cc:1844] UNKNOWN: AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/tmp/__autograph_generated_filewhy2r9h7.py\", line 16, in _lookup_label\n",
      "    image_path = ag__.converted_call(ag__.ld(image_path).decode, ('utf-8',), None, fscope_1)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor.py\", line 260, in __getattr__\n",
      "    self.__getattribute__(name)\n",
      "\n",
      "AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "\n",
      "\n",
      "2025-03-28 17:16:07.497352: W tensorflow/core/framework/op_kernel.cc:1844] UNKNOWN: AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/tmp/__autograph_generated_filewhy2r9h7.py\", line 16, in _lookup_label\n",
      "    image_path = ag__.converted_call(ag__.ld(image_path).decode, ('utf-8',), None, fscope_1)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor.py\", line 260, in __getattr__\n",
      "    self.__getattribute__(name)\n",
      "\n",
      "AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "\n",
      "\n",
      "2025-03-28 17:16:07.502335: W tensorflow/core/framework/op_kernel.cc:1844] UNKNOWN: AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/tmp/__autograph_generated_filewhy2r9h7.py\", line 16, in _lookup_label\n",
      "    image_path = ag__.converted_call(ag__.ld(image_path).decode, ('utf-8',), None, fscope_1)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor.py\", line 260, in __getattr__\n",
      "    self.__getattribute__(name)\n",
      "\n",
      "AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "\n",
      "\n",
      "2025-03-28 17:16:07.504362: W tensorflow/core/framework/op_kernel.cc:1844] UNKNOWN: AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/tmp/__autograph_generated_filewhy2r9h7.py\", line 16, in _lookup_label\n",
      "    image_path = ag__.converted_call(ag__.ld(image_path).decode, ('utf-8',), None, fscope_1)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor.py\", line 260, in __getattr__\n",
      "    self.__getattribute__(name)\n",
      "\n",
      "AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "\n",
      "\n",
      "2025-03-28 17:16:07.511009: W tensorflow/core/framework/op_kernel.cc:1844] UNKNOWN: AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/tmp/__autograph_generated_filewhy2r9h7.py\", line 16, in _lookup_label\n",
      "    image_path = ag__.converted_call(ag__.ld(image_path).decode, ('utf-8',), None, fscope_1)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor.py\", line 260, in __getattr__\n",
      "    self.__getattribute__(name)\n",
      "\n",
      "AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "\n",
      "\n",
      "2025-03-28 17:16:07.514057: W tensorflow/core/framework/op_kernel.cc:1844] UNKNOWN: AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/tmp/__autograph_generated_filewhy2r9h7.py\", line 16, in _lookup_label\n",
      "    image_path = ag__.converted_call(ag__.ld(image_path).decode, ('utf-8',), None, fscope_1)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor.py\", line 260, in __getattr__\n",
      "    self.__getattribute__(name)\n",
      "\n",
      "AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "\n",
      "\n",
      "2025-03-28 17:16:07.519051: W tensorflow/core/framework/op_kernel.cc:1844] UNKNOWN: AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/tmp/__autograph_generated_filewhy2r9h7.py\", line 16, in _lookup_label\n",
      "    image_path = ag__.converted_call(ag__.ld(image_path).decode, ('utf-8',), None, fscope_1)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor.py\", line 260, in __getattr__\n",
      "    self.__getattribute__(name)\n",
      "\n",
      "AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "\n",
      "\n",
      "2025-03-28 17:16:07.521919: W tensorflow/core/framework/op_kernel.cc:1844] UNKNOWN: AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/tmp/__autograph_generated_filewhy2r9h7.py\", line 16, in _lookup_label\n",
      "    image_path = ag__.converted_call(ag__.ld(image_path).decode, ('utf-8',), None, fscope_1)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor.py\", line 260, in __getattr__\n",
      "    self.__getattribute__(name)\n",
      "\n",
      "AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "\n",
      "\n",
      "2025-03-28 17:16:07.524982: W tensorflow/core/framework/op_kernel.cc:1844] UNKNOWN: AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/tmp/__autograph_generated_filewhy2r9h7.py\", line 16, in _lookup_label\n",
      "    image_path = ag__.converted_call(ag__.ld(image_path).decode, ('utf-8',), None, fscope_1)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor.py\", line 260, in __getattr__\n",
      "    self.__getattribute__(name)\n",
      "\n",
      "AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "\n",
      "\n",
      "2025-03-28 17:16:07.528402: W tensorflow/core/framework/op_kernel.cc:1844] UNKNOWN: AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/tmp/__autograph_generated_filewhy2r9h7.py\", line 16, in _lookup_label\n",
      "    image_path = ag__.converted_call(ag__.ld(image_path).decode, ('utf-8',), None, fscope_1)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor.py\", line 260, in __getattr__\n",
      "    self.__getattribute__(name)\n",
      "\n",
      "AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "\n",
      "\n",
      "2025-03-28 17:16:07.528681: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: UNKNOWN: Error in user-defined function passed to ParallelMapDatasetV2:295 transformation with iterator: Iterator::Root::Prefetch::FiniteTake::ParallelMapV2: AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/tmp/__autograph_generated_filewhy2r9h7.py\", line 16, in _lookup_label\n",
      "    image_path = ag__.converted_call(ag__.ld(image_path).decode, ('utf-8',), None, fscope_1)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor.py\", line 260, in __getattr__\n",
      "    self.__getattribute__(name)\n",
      "\n",
      "AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "\n",
      "\n",
      "\t [[{{node EagerPyFunc}}]]\n",
      "2025-03-28 17:16:07.543024: W tensorflow/core/framework/op_kernel.cc:1844] UNKNOWN: AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/tmp/__autograph_generated_filewhy2r9h7.py\", line 16, in _lookup_label\n",
      "    image_path = ag__.converted_call(ag__.ld(image_path).decode, ('utf-8',), None, fscope_1)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor.py\", line 260, in __getattr__\n",
      "    self.__getattribute__(name)\n",
      "\n",
      "AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "\n",
      "\n",
      "2025-03-28 17:16:07.544696: W tensorflow/core/framework/op_kernel.cc:1844] UNKNOWN: AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/tmp/__autograph_generated_filewhy2r9h7.py\", line 16, in _lookup_label\n",
      "    image_path = ag__.converted_call(ag__.ld(image_path).decode, ('utf-8',), None, fscope_1)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor.py\", line 260, in __getattr__\n",
      "    self.__getattribute__(name)\n",
      "\n",
      "AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "\n",
      "\n",
      "2025-03-28 17:16:07.582850: W tensorflow/core/framework/op_kernel.cc:1844] UNKNOWN: AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/tmp/__autograph_generated_filewhy2r9h7.py\", line 16, in _lookup_label\n",
      "    image_path = ag__.converted_call(ag__.ld(image_path).decode, ('utf-8',), None, fscope_1)\n",
      "\n",
      "  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor.py\", line 260, in __getattr__\n",
      "    self.__getattribute__(name)\n",
      "\n",
      "AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Error in user-defined function passed to ParallelMapDatasetV2:295 transformation with iterator: Iterator::Root::Prefetch::FiniteTake::ParallelMapV2: AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\nTraceback (most recent call last):\n\n  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    return func(device, token, args)\n\n  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n    outputs = self._call(device, args)\n\n  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n    ret = self._func(*args)\n\n  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/tmp/__autograph_generated_filewhy2r9h7.py\", line 16, in _lookup_label\n    image_path = ag__.converted_call(ag__.ld(image_path).decode, ('utf-8',), None, fscope_1)\n\n  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor.py\", line 260, in __getattr__\n    self.__getattribute__(name)\n\nAttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m im, label \u001b[38;5;129;01min\u001b[39;00m ds_images\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(im\u001b[38;5;241m.\u001b[39mshape, label)\n",
      "File \u001b[0;32m~/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:826\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    825\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:776\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 776\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3086\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3084\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3085\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 3086\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3087\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   3088\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:6006\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6004\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   6005\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 6006\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mUnknownError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Error in user-defined function passed to ParallelMapDatasetV2:295 transformation with iterator: Iterator::Root::Prefetch::FiniteTake::ParallelMapV2: AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\nTraceback (most recent call last):\n\n  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    return func(device, token, args)\n\n  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n    outputs = self._call(device, args)\n\n  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n    ret = self._func(*args)\n\n  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/tmp/__autograph_generated_filewhy2r9h7.py\", line 16, in _lookup_label\n    image_path = ag__.converted_call(ag__.ld(image_path).decode, ('utf-8',), None, fscope_1)\n\n  File \"/home/alf/git-repos/UFVDeepLearning/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor.py\", line 260, in __getattr__\n    self.__getattribute__(name)\n\nAttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "for im, label in ds_images.take(1):\n",
    "    print(im.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class    \n",
       "fish         13\n",
       "jellyfish    11\n",
       "shark        11\n",
       "stingray     10\n",
       "penguin       7\n",
       "puffin        6\n",
       "starfish      5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "# Rutas de los datos originales\n",
    "base_dir = \"data/practica_1_dataset\"\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "valid_dir = os.path.join(base_dir, \"valid\")\n",
    "\n",
    "# Rutas de los datos procesados (donde se guardarán las imágenes originales y sintéticas)\n",
    "processed_base = \"data/processed\"\n",
    "processed_train_dir = os.path.join(processed_base, \"train\")\n",
    "processed_validation_dir = os.path.join(processed_base, \"validation\")\n",
    "\n",
    "# Se crean los directorios de salida si no existen\n",
    "os.makedirs(processed_train_dir, exist_ok=True)\n",
    "os.makedirs(processed_validation_dir, exist_ok=True)\n",
    "\n",
    "# Mapeo de clases a números (para la máscara)\n",
    "class_mapping = {\n",
    "    \"fish\": 1,\n",
    "    \"jellyfish\": 2,\n",
    "    \"penguin\": 3,\n",
    "    \"shark\": 4,\n",
    "    \"puffin\": 5,\n",
    "    \"stingray\": 6,\n",
    "    \"starfish\": 7\n",
    "}\n",
    "\n",
    "def process_folder(input_folder, output_folder, annotations_df):\n",
    "    \"\"\"\n",
    "    Procesa las imágenes de input_folder y guarda en output_folder:\n",
    "      - Una copia de la imagen original.\n",
    "      - Una imagen sintética en la que se \"borran\" (reemplazan) los píxeles de la clase predominante \n",
    "        usando el color medio calculado fuera de dicha región. Esta imagen se guarda con el sufijo \n",
    "        \"_synthetic\" antes de la extensión.\n",
    "    Además, registra en un CSV la información (nombre de imagen, clase predominante y área) de cada imagen.\n",
    "    \"\"\"\n",
    "    dataset_info = []  # Lista para almacenar la información de cada imagen procesada\n",
    "\n",
    "    # Obtener archivos de imagen (considerando las extensiones jpg, jpeg y png)\n",
    "    image_files = [f for f in os.listdir(input_folder) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "    image_files = annotations_df[\"image\"].unique()\n",
    "\n",
    "    for image_name in tqdm(image_files, desc=f\"Procesando {os.path.basename(input_folder)}\"):\n",
    "        image_path = os.path.join(input_folder, image_name)\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al abrir {image_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        width, height = image.size\n",
    "\n",
    "        # Crear la máscara con fondo = 0\n",
    "        mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "        # Filtrar las anotaciones para la imagen\n",
    "        image_annotations = annotations_df[annotations_df['filename'] == image_name]\n",
    "        for _, row in image_annotations.iterrows():\n",
    "            cls = row['class']\n",
    "            if cls in class_mapping:\n",
    "                class_id = class_mapping[cls]\n",
    "                xmin, ymin, xmax, ymax = int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])\n",
    "                mask[ymin:ymax, xmin:xmax] = class_id\n",
    "\n",
    "        # Determinar la clase predominante (excluyendo el fondo)\n",
    "        uniques, counts = np.unique(mask, return_counts=True)\n",
    "        pixel_count_dict = dict(zip(uniques, counts))\n",
    "        pixel_count_dict.pop(0, None)  # Se elimina el fondo\n",
    "        if pixel_count_dict:\n",
    "            predominant_class_id = max(pixel_count_dict, key=pixel_count_dict.get)  # id with more pixels\n",
    "            predominant_area = pixel_count_dict[predominant_class_id]  # num pixels\n",
    "            # predominant_class_label = [label for label, idx in class_mapping.items() if idx == predominant_class_id][0]\n",
    "            predominant_class_label = class_mapping[predominant_class_id]\n",
    "        else:\n",
    "            predominant_class_label = None\n",
    "            predominant_area = 0\n",
    "\n",
    "        # Registrar la información en el dataset\n",
    "        dataset_info.append({\n",
    "            \"filename\": image_name,\n",
    "            \"predominant_class\": predominant_class_label,\n",
    "            \"area\": predominant_area\n",
    "        })\n",
    "        {\n",
    "            \"filename\": [].append()\n",
    "        }\n",
    "\n",
    "        # Copiar la imagen original al directorio procesado\n",
    "        dest_original_path = os.path.join(output_folder, image_name)\n",
    "        shutil.copy(image_path, dest_original_path)\n",
    "\n",
    "        # Generar la imagen sintética\n",
    "        image_array = np.array(image)\n",
    "        if predominant_class_label is not None:\n",
    "            mask_predominant = (mask == predominant_class_id)\n",
    "            # Calcular el color medio de los píxeles fuera de la región predominante\n",
    "            if np.any(~mask_predominant):\n",
    "                mean_color = image_array[~mask_predominant].mean(axis=0).astype(np.uint8)\n",
    "            else:\n",
    "                mean_color = np.array([0, 0, 0], dtype=np.uint8)\n",
    "            synthetic_image_array = image_array.copy()\n",
    "            synthetic_image_array[mask_predominant] = mean_color\n",
    "        else:\n",
    "            synthetic_image_array = image_array.copy()\n",
    "\n",
    "        # Se genera el nombre de la imagen sintética con el sufijo \"_synthetic\" antes de la extensión .jpg\n",
    "        file_base, _ = os.path.splitext(image_name)\n",
    "        synthetic_name = f\"{file_base}_synthetic.jpg\"\n",
    "        synthetic_image = Image.fromarray(synthetic_image_array)\n",
    "        synthetic_image.save(os.path.join(output_folder, synthetic_name))\n",
    "    \n",
    "    # Guardar el CSV con la información de las imágenes en el mismo directorio de salida\n",
    "    csv_output_path = os.path.join(output_folder, \"new_dataset.csv\")\n",
    "    pd.DataFrame(dataset_info).to_csv(csv_output_path, index=False)\n",
    "    print(f\"Procesamiento completado para {os.path.basename(input_folder)}. CSV guardado en {csv_output_path}\")\n",
    "\n",
    "# Leer los archivos de anotaciones respectivos de cada carpeta\n",
    "train_annotations_path = os.path.join(train_dir, \"annotations.csv\")\n",
    "valid_annotations_path = os.path.join(valid_dir, \"annotations.csv\")\n",
    "\n",
    "train_annotations = pd.read_csv(train_annotations_path)\n",
    "valid_annotations = pd.read_csv(valid_annotations_path)\n",
    "\n",
    "# Procesar el conjunto de entrenamiento\n",
    "process_folder(train_dir, processed_train_dir, train_annotations)\n",
    "\n",
    "# Procesar el conjunto de validación (se guarda en la carpeta \"validation\")\n",
    "process_folder(valid_dir, processed_validation_dir, valid_annotations)\n",
    "\n",
    "print(\"Todos los conjuntos han sido procesados correctamente.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
