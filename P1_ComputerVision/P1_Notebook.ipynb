{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practica 1 - Computer Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data zipfile already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gdown\n",
    "\n",
    "# Crear el directorio de datos si no existe\n",
    "data_dir = \"data\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "# URL de Google Drive en formato correcto para gdown\n",
    "url = \"https://drive.google.com/uc?id=1iGBv-VT5mm1RiouD-U2qWcU3BYqp2OwE\"\n",
    "zip_filename = \"practica_1_dataset.zip\"\n",
    "zip_path = os.path.join(data_dir, zip_filename)\n",
    "\n",
    "# Descargar el archivo\n",
    "if not os.path.exists(zip_path):\n",
    "    gdown.download(url, zip_path, quiet=False)\n",
    "else:\n",
    "    print(\"Data zipfile already exists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "data_dir = \"data\"\n",
    "zip_filename = \"practica_1_dataset.zip\"\n",
    "zip_path = os.path.join(data_dir, zip_filename)\n",
    "subfolders = [\"test\", \"train\", \"valid\"]\n",
    "full_paths = [os.path.join(data_dir, folder) for folder in subfolders]\n",
    "\n",
    "if not all(os.path.isdir(path) for path in full_paths):\n",
    "    with ZipFile(zip_path, 'r') as zf:\n",
    "        with ThreadPoolExecutor() as exe:\n",
    "            for file in zf.namelist():\n",
    "                if not file.startswith(\"__MACOSX\"):\n",
    "                    exe.submit(zf.extract, file, path=data_dir)\n",
    "else:\n",
    "    print(\"test, train and valid folders already exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total image files in test: 63\n",
      "Filenames shape: TensorSpec(shape=(), dtype=tf.string, name=None)\n",
      "Total image files in train: 448\n",
      "Filenames shape: TensorSpec(shape=(), dtype=tf.string, name=None)\n",
      "Total image files in valid: 127\n",
      "Filenames shape: TensorSpec(shape=(), dtype=tf.string, name=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'data/valid/IMG_2277_jpeg_jpg.rf.86c72d6192da48d941ffa957f4780665.jpg'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "for folder in subfolders:\n",
    "    folder_path = os.path.join(data_dir, folder)\n",
    "    ds_files = tf.data.Dataset.list_files(folder_path + \"/*.jpg\", shuffle=False)\n",
    "    print(f\"Total image files in {folder}: {len(ds_files)}\")\n",
    "    print(\"Filenames shape:\", ds_files.element_spec)\n",
    "\n",
    "example = next(ds_files.take(1).as_numpy_iterator())\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape = (584, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG_2526_jpeg_jpg.rf.003e1d1d41bcd204df731b85c...</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>puffin</td>\n",
       "      <td>406</td>\n",
       "      <td>457</td>\n",
       "      <td>497</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG_2526_jpeg_jpg.rf.003e1d1d41bcd204df731b85c...</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>puffin</td>\n",
       "      <td>18</td>\n",
       "      <td>705</td>\n",
       "      <td>82</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG_2526_jpeg_jpg.rf.003e1d1d41bcd204df731b85c...</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>puffin</td>\n",
       "      <td>51</td>\n",
       "      <td>426</td>\n",
       "      <td>116</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG_2526_jpeg_jpg.rf.003e1d1d41bcd204df731b85c...</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>puffin</td>\n",
       "      <td>428</td>\n",
       "      <td>331</td>\n",
       "      <td>504</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG_2526_jpeg_jpg.rf.003e1d1d41bcd204df731b85c...</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>puffin</td>\n",
       "      <td>0</td>\n",
       "      <td>613</td>\n",
       "      <td>21</td>\n",
       "      <td>658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  width  height   class  \\\n",
       "0  IMG_2526_jpeg_jpg.rf.003e1d1d41bcd204df731b85c...    768    1024  puffin   \n",
       "1  IMG_2526_jpeg_jpg.rf.003e1d1d41bcd204df731b85c...    768    1024  puffin   \n",
       "2  IMG_2526_jpeg_jpg.rf.003e1d1d41bcd204df731b85c...    768    1024  puffin   \n",
       "3  IMG_2526_jpeg_jpg.rf.003e1d1d41bcd204df731b85c...    768    1024  puffin   \n",
       "4  IMG_2526_jpeg_jpg.rf.003e1d1d41bcd204df731b85c...    768    1024  puffin   \n",
       "\n",
       "   xmin  ymin  xmax  ymax  \n",
       "0   406   457   497   533  \n",
       "1    18   705    82   759  \n",
       "2    51   426   116   475  \n",
       "3   428   331   504   376  \n",
       "4     0   613    21   658  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_dir = \"data\"\n",
    "df = pd.read_csv(os.path.join(data_dir, \"test\", \"annotations.csv\"))\n",
    "print(f\"{df.shape = }\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['IMG_2289_jpeg_jpg.rf.fe2a7a149e7b11f2313f5a7b30386e85.jpg',\n",
       "        'IMG_2301_jpeg_jpg.rf.2c19ae5efbd1f8611b5578125f001695.jpg',\n",
       "        'IMG_2319_jpeg_jpg.rf.6e20bf97d17b74a8948aa48776c40454.jpg',\n",
       "        'IMG_2347_jpeg_jpg.rf.7c71ac4b9301eb358cd4a832844dedcb.jpg',\n",
       "        'IMG_2354_jpeg_jpg.rf.396e872c7fb0a95e911806986995ee7a.jpg'],\n",
       "       dtype=object),\n",
       " array(['puffin', 'penguin', 'penguin', 'penguin', 'penguin'], dtype=object))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def annotation_to_labels(annotations_path):\n",
    "    # Load the annotations\n",
    "    df = pd.read_csv(annotations_path)\n",
    "\n",
    "    # Count the number of instances of each class per image\n",
    "    count_class = df.groupby([\"filename\", \"class\"]).size()\n",
    "\n",
    "    # Compute the area of each bounding box\n",
    "    df[\"area\"] = (df[\"xmax\"] - df[\"xmin\"]) * (df[\"ymax\"] - df[\"ymin\"])\n",
    "\n",
    "    # Compute the area of each class per image\n",
    "    area_class = df.groupby([\"filename\", \"class\"])[\"area\"].sum()\n",
    "    \n",
    "    # Compute the score as AREA * COUNT\n",
    "    score = pd.Series(area_class * count_class, name=\"score\").reset_index()\n",
    "\n",
    "    # Group by filename and get the class with the highest score\n",
    "    df_labels = score.groupby(\"filename\").max().reset_index()\n",
    "\n",
    "    return df_labels[\"filename\"].values, df_labels[\"class\"].values\n",
    "\n",
    "data_dir = \"data\"\n",
    "filenames, labels = annotation_to_labels(os.path.join(data_dir, \"test\", \"annotations.csv\"))\n",
    "filenames[:5], labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "def organize_by_label(filenames, labels, data_dir):\n",
    "    # Define input and output paths\n",
    "    filepaths = np.char.add(data_dir + os.sep, filenames)\n",
    "    organized_filepaths = np.char.add(data_dir + os.sep + labels + os.sep, filenames)\n",
    "\n",
    "\n",
    "    for label in np.unique(labels):\n",
    "        os.makedirs(data_dir + os.sep + label, exist_ok=True)\n",
    "    \n",
    "    def move_file(src, dest):\n",
    "        try:\n",
    "            shutil.move(src, dest)\n",
    "            return True  # File moved successfully\n",
    "        except FileNotFoundError:\n",
    "            return False  # File does not exist\n",
    "        except Exception as e:\n",
    "            return f\"Error: {e}\"\n",
    "\n",
    "    return np.vectorize(move_file)(filepaths, organized_filepaths)\n",
    "\n",
    "data_dir = os.path.join(\"data\", \"test\")\n",
    "organize_by_label(filenames, labels, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 files belonging to 0 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No images found in directory data/train. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m set_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m ds \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     name: tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(\n\u001b[1;32m      4\u001b[0m         os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, name),\n\u001b[1;32m      5\u001b[0m         image_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m),\n\u001b[1;32m      6\u001b[0m         label_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m set_names\n\u001b[1;32m     10\u001b[0m }\n\u001b[1;32m     11\u001b[0m ds\n",
      "Cell \u001b[0;32mIn[34], line 3\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m set_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      2\u001b[0m ds \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m----> 3\u001b[0m     name: \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_dataset_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m set_names\n\u001b[1;32m     10\u001b[0m }\n\u001b[1;32m     11\u001b[0m ds\n",
      "File \u001b[0;32m~/git-repos/PracticasDeepLearning/.venv/lib/python3.10/site-packages/keras/src/utils/image_dataset_utils.py:329\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, verbose)\u001b[0m\n\u001b[1;32m    325\u001b[0m image_paths, labels \u001b[38;5;241m=\u001b[39m dataset_utils\u001b[38;5;241m.\u001b[39mget_training_or_validation_split(\n\u001b[1;32m    326\u001b[0m     image_paths, labels, validation_split, subset\n\u001b[1;32m    327\u001b[0m )\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m image_paths:\n\u001b[0;32m--> 329\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo images found in directory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAllowed formats: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mALLOWLIST_FORMATS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    332\u001b[0m     )\n\u001b[1;32m    334\u001b[0m dataset \u001b[38;5;241m=\u001b[39m paths_and_labels_to_dataset(\n\u001b[1;32m    335\u001b[0m     image_paths\u001b[38;5;241m=\u001b[39mimage_paths,\n\u001b[1;32m    336\u001b[0m     image_size\u001b[38;5;241m=\u001b[39mimage_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    347\u001b[0m     seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[1;32m    348\u001b[0m )\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: No images found in directory data/train. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')"
     ]
    }
   ],
   "source": [
    "set_names = [\"train\", \"valid\", \"test\"]\n",
    "\n",
    "ds = {\n",
    "    name: tf.keras.utils.image_dataset_from_directory(\n",
    "        os.path.join(data_dir, name),\n",
    "        image_size=(224, 224),\n",
    "        label_mode=\"int\",\n",
    "        batch_size=None,\n",
    "    )\n",
    "    for name in set_names\n",
    "}\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 63 files belonging to 7 classes.\n",
      "(1, 224, 224, 3) (1,)\n"
     ]
    }
   ],
   "source": [
    "data_dir = pathlib.Path(\"data/test/\")\n",
    "ds_test = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    image_size=(224, 224),\n",
    "    label_mode=\"int\",\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "for el in ds_test.take(10):\n",
    "    image, label = el\n",
    "    print(image.shape, label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None,), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "ds_files = tf.data.Dataset.list_files(\"data/test/\" + '*.jpg', shuffle=False)\n",
    "df = pd.read_csv(\"data/test/annotations.csv\")\n",
    "df[\"class\"] = pd.Categorical(df[\"class\"])\n",
    "ds_images = (\n",
    "    ds_files\n",
    "    .shuffle(len(ds_files))\n",
    "    .cache()\n",
    "    .map(lambda x: (get_image(x), get_label(x, df)), num_parallel_calls=AUTOTUNE)\n",
    ")\n",
    "\n",
    "print(\"Total images:\", len(ds_images))\n",
    "print(\"Image shape:\", ds_images.element_spec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
