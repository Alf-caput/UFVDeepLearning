{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c968420",
   "metadata": {},
   "source": [
    "# Practica 2 - Natural Language processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc8f458",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b54bd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras import Model, Input, layers\n",
    "from tensorflow.keras.layers import Embedding, Dot, Reshape, Dense\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import skipgrams\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import skipgrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d7982c",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f57b9d",
   "metadata": {},
   "source": [
    "## Descarga y proceso de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec4e58f",
   "metadata": {},
   "source": [
    "### Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41d34a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fallo con encoding utf-8, probando siguiente...\n",
      "Cargado 'train.csv' con encoding latin1\n",
      "Cargado 'test.csv' con encoding latin1\n",
      "Train shape: (27481, 10)\n",
      "Test  shape: (4815, 9)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Directorio portable a P2_NaturalLanguageProcessing/data\n",
    "cwd      = os.getcwd()\n",
    "data_dir = os.path.join(cwd, 'data')\n",
    "\n",
    "# 2. Rutas a los CSV\n",
    "train_path = os.path.join(data_dir, 'train.csv')\n",
    "test_path  = os.path.join(data_dir, 'test.csv')\n",
    "\n",
    "# 3. Lista de codificaciones a probar\n",
    "encodings = ['utf-8', 'latin1', 'iso-8859-1', 'cp1252']\n",
    "\n",
    "def load_csv(path, enc_list):\n",
    "    for enc in enc_list:\n",
    "        try:\n",
    "            df = pd.read_csv(path, encoding=enc)\n",
    "            print(f\"Cargado '{os.path.basename(path)}' con encoding {enc}\")\n",
    "            return df, enc\n",
    "        except UnicodeDecodeError:\n",
    "            print(f\"Fallo con encoding {enc}, probando siguiente...\")\n",
    "    raise ValueError(f\"No se pudo decodificar {path} con las codificaciones {enc_list}\")\n",
    "\n",
    "# 4. Cargar ambos conjuntos usando la misma codificación\n",
    "train_df, used_enc = load_csv(train_path, encodings)\n",
    "test_df, _      = load_csv(test_path, [used_enc])\n",
    "\n",
    "# 5. Verificación\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test  shape: {test_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f1bd05",
   "metadata": {},
   "source": [
    "### Exploración y limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61a5800b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32296 entries, 0 to 32295\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   textID            31015 non-null  object \n",
      " 1   text              31014 non-null  object \n",
      " 2   selected_text     27480 non-null  object \n",
      " 3   sentiment         31015 non-null  object \n",
      " 4   Time of Tweet     31015 non-null  object \n",
      " 5   Age of User       31015 non-null  object \n",
      " 6   Country           31015 non-null  object \n",
      " 7   Population -2020  31015 non-null  float64\n",
      " 8   Land Area (Km²)   31015 non-null  float64\n",
      " 9   Density (P/Km²)   31015 non-null  float64\n",
      "dtypes: float64(3), object(7)\n",
      "memory usage: 2.5+ MB\n",
      "None\n",
      "       textID                                               text  \\\n",
      "0  cb774db0d1                I`d have responded, if I were going   \n",
      "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
      "2  088c60f138                          my boss is bullying me...   \n",
      "3  9642c003ef                     what interview! leave me alone   \n",
      "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
      "\n",
      "                         selected_text sentiment Time of Tweet Age of User  \\\n",
      "0  I`d have responded, if I were going   neutral       morning        0-20   \n",
      "1                             Sooo SAD  negative          noon       21-30   \n",
      "2                          bullying me  negative         night       31-45   \n",
      "3                       leave me alone  negative       morning       46-60   \n",
      "4                        Sons of ****,  negative          noon       60-70   \n",
      "\n",
      "       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n",
      "0  Afghanistan        38928346.0         652860.0             60.0  \n",
      "1      Albania         2877797.0          27400.0            105.0  \n",
      "2      Algeria        43851044.0        2381740.0             18.0  \n",
      "3      Andorra           77265.0            470.0            164.0  \n",
      "4       Angola        32866272.0        1246700.0             26.0  \n",
      "Total de muestras: 32296\n",
      "Palabras únicas encontradas: 28490\n",
      "Top 10 palabras más frecuentes: [('i', 18870), ('to', 11249), ('the', 10200), ('a', 7609), ('my', 6264), ('it', 6123), ('you', 6040), ('and', 5827), ('is', 4490), ('in', 4279)]\n",
      "BUFFER_SIZE = 32768\n",
      "BATCH_SIZE = 128\n",
      "VOCAB_SIZE = 8192\n"
     ]
    }
   ],
   "source": [
    "# 5. Juntar los DataFrames para facilitar el preprocesado\n",
    "data_df = pd.concat([train_df, test_df], ignore_index=True)      # concatenación[2]\n",
    "\n",
    "# 6. Inspeccionar estructura básica\n",
    "print(data_df.info())\n",
    "print(data_df.head())\n",
    "\n",
    "# 7. Contar palabras únicas en la columna 'text' para estimar VOCAB_SIZE\n",
    "all_text = ' '.join(data_df['text'].astype(str)).lower()\n",
    "words = re.findall(r'\\b\\w+\\b', all_text)\n",
    "word_counts = Counter(words)\n",
    "unique_words = len(word_counts)\n",
    "\n",
    "print(f\"Total de muestras: {data_df.shape[0]}\")\n",
    "print(f\"Palabras únicas encontradas: {unique_words}\")\n",
    "print(\"Top 10 palabras más frecuentes:\", word_counts.most_common(10))\n",
    "\n",
    "# 8. Definir parámetros para TensorFlow/Keras\n",
    "BUFFER_SIZE = 32768      # chivo mayor al dataset para buen shuffle 2^15\n",
    "BATCH_SIZE = 128        # potencia de 2 adecuada para GPU\n",
    "VOCAB_SIZE = 8192      # tamaño del vocabulario[4]\n",
    "                 \n",
    "print(\"BUFFER_SIZE =\", BUFFER_SIZE)\n",
    "print(\"BATCH_SIZE =\", BATCH_SIZE)\n",
    "print(\"VOCAB_SIZE =\", VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28aad5dd",
   "metadata": {},
   "source": [
    "### Preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88eb256",
   "metadata": {},
   "source": [
    "#### Creación del corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d2350be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeros 5 textos filtrados: ['i d have responded if i were going', 'sooo sad i will miss you here in san diego', 'my boss is me', 'what interview leave me alone', 'sons of why couldn t they put them on the releases we already bought']\n",
      "Primeras 5 secuencias: [[1, 163, 19, 7648, 71, 1, 151, 49], [421, 117, 1, 63, 94, 7, 91, 10, 1447, 2230], [5, 1410, 9, 16], [51, 1193, 350, 16, 495], [4254, 13, 118, 472, 14, 72, 332, 131, 17, 3, 7649, 50, 210, 569]]\n",
      "Tamaño de vocabulario efectivo: 8152\n"
     ]
    }
   ],
   "source": [
    "# 1. Seleccionar las 4 096 palabras más frecuentes\n",
    "most_common_words = {w for w, _ in word_counts.most_common(VOCAB_SIZE)}\n",
    "\n",
    "# 2. Filtrar cada texto para quedarnos solo con tokens en el top 4 096\n",
    "corpus_filtered = []\n",
    "for text in data_df['text'].dropna().astype(str):\n",
    "    tokens = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    filtered_tokens = [t for t in tokens if t in most_common_words]\n",
    "    corpus_filtered.append(\" \".join(filtered_tokens))\n",
    "\n",
    "# 3. Tokenizar el corpus filtrado\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(corpus_filtered)\n",
    "\n",
    "# 4. Convertir textos a secuencias de índices\n",
    "sequences = tokenizer.texts_to_sequences(corpus_filtered)\n",
    "\n",
    "# 5. Diccionarios de mapeo y tamaño final de vocabulario\n",
    "word2idx = tokenizer.word_index\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "vocab_size = min(len(word2idx) + 1, VOCAB_SIZE)\n",
    "\n",
    "# 6. Mostrar resultados de prueba\n",
    "print(\"Primeros 5 textos filtrados:\", corpus_filtered[:5])\n",
    "print(\"Primeras 5 secuencias:\", sequences[:5])\n",
    "print(\"Tamaño de vocabulario efectivo:\", vocab_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7606597",
   "metadata": {},
   "source": [
    "#### Generación de los pares de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c56d118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window=2: 1384586 pares generados\n",
      "Window=4: 2530442 pares generados\n"
     ]
    }
   ],
   "source": [
    "# Parámetros generales\n",
    "# vocab_size_eff    = vocab_size    # p.ej. 8192\n",
    "negative_samples  = 0.0\n",
    "seed_value        = 42\n",
    "\n",
    "# Ventanas para generar pares\n",
    "window_sizes = [2, 4]\n",
    "\n",
    "# Contenedor de pares por tamaño de ventana\n",
    "pairs_by_window = {}\n",
    "\n",
    "for w in window_sizes:\n",
    "    pairs = []\n",
    "    for seq in sequences:\n",
    "        if len(seq) < 2:\n",
    "            continue\n",
    "        # Generar solo pares positivos con skipgrams\n",
    "        pos_pairs, _ = skipgrams(\n",
    "            sequence=seq,\n",
    "            vocabulary_size=vocab_size,\n",
    "            window_size=w,\n",
    "            negative_samples=negative_samples,\n",
    "            shuffle=True,\n",
    "            seed=seed_value\n",
    "        )\n",
    "        pairs.extend(pos_pairs)\n",
    "\n",
    "    # Convertir a arrays target/context\n",
    "    if pairs:\n",
    "        t, c = zip(*pairs)\n",
    "        targets  = np.array(t, dtype='int32')\n",
    "        contexts = np.array(c, dtype='int32')\n",
    "    else:\n",
    "        targets  = np.zeros((0,), dtype='int32')\n",
    "        contexts = np.zeros((0,), dtype='int32')\n",
    "\n",
    "    pairs_by_window[w] = {\n",
    "        'pairs':   pairs,\n",
    "        'targets': targets,\n",
    "        'contexts':contexts\n",
    "    }\n",
    "    print(f\"Window={w}: {len(pairs)} pares generados\")\n",
    "\n",
    "# Ejemplo de acceso:\n",
    "# pairs_by_window[2]['targets'], pairs_by_window[2]['contexts']\n",
    "# pairs_by_window[4]['targets'], pairs_by_window[4]['contexts']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0ad6f6",
   "metadata": {},
   "source": [
    "#### Integer-encoding\n",
    "Un poco de teoría de los dos encoders:\n",
    "\n",
    "- Integer encoding: X_target y X_context son vectores de enteros donde cada valor es el índice de palabra en el vocabulario. Es lo adecuado cuando se usa una capa Embedding, ya que Keras transforma internamente cada índice en su vector embebido.\n",
    "\n",
    "- One-hot encoding: cada índice se convierte en un vector binario de longitud vocab_size con un único 1 en la posición correspondiente al índice. Ocupa mucha más memoria y rara vez es necesario si tu primer bloque es Embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c405434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ventana = 2 ---\n",
      "Número de pares: 1384586\n",
      "X_target shape: (1384586,)\n",
      "X_context shape: (1384586,)\n",
      "y_train shape: (1384586,)\n",
      "\n",
      "--- Ventana = 4 ---\n",
      "Número de pares: 2530442\n",
      "X_target shape: (2530442,)\n",
      "X_context shape: (2530442,)\n",
      "y_train shape: (2530442,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Suponemos que ya existe:\n",
    "#  - pairs_by_window: dict con keys 2 y 4, cada uno contiene 'targets' y 'contexts'\n",
    "#  - vocab_size: tamaño efectivo del vocabulario (p.ej. 8192)\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for w, data in pairs_by_window.items():\n",
    "    # 1. Extraer targets y contexts\n",
    "    targets  = data['targets']    # array shape (n_pairs,)\n",
    "    contexts = data['contexts']   # array shape (n_pairs,)\n",
    "    \n",
    "    # 2. Crear X_train como representación dispersa (enteros)\n",
    "    X_target  = targets\n",
    "    X_context = contexts\n",
    "    X_train   = [X_target, X_context]\n",
    "    \n",
    "    # 3. Etiquetas positivas\n",
    "    y_train = np.ones((len(targets),), dtype='int32')\n",
    "    \n",
    "    # 4. Almacenar en el nuevo dict\n",
    "    datasets[w] = {\n",
    "        'X_train': X_train,\n",
    "        'y_train': y_train\n",
    "    }\n",
    "    \n",
    "    # 5. Mostrar shapes de comprobación\n",
    "    print(f\"--- Ventana = {w} ---\")\n",
    "    print(\"Número de pares:\", len(targets))\n",
    "    print(\"X_target shape:\",  X_target.shape)\n",
    "    print(\"X_context shape:\", X_context.shape)\n",
    "    print(\"y_train shape:\",    y_train.shape)\n",
    "    print()\n",
    "\n",
    "# Acceso posterior:\n",
    "# datasets[2]['X_train'], datasets[2]['y_train']\n",
    "# datasets[4]['X_train'], datasets[4]['y_train']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96e6680",
   "metadata": {},
   "source": [
    "## Arquitectura y ejecucción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3cfdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando Skip-Gram: window=2, embed_dim=45\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jbarc\\Documents\\Deep learning\\UFVDeepLearning\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10818/10818\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0267\n",
      "Epoch 2/10\n",
      "\u001b[1m10818/10818\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4643e-07\n",
      "Epoch 3/10\n",
      "\u001b[1m10818/10818\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0106e-08\n",
      "Epoch 4/10\n",
      "\u001b[1m10818/10818\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0869e-08\n",
      "Epoch 5/10\n",
      "\u001b[1m10818/10818\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4148e-08\n",
      "Epoch 6/10\n",
      "\u001b[1m10818/10818\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0934e-08\n",
      "Epoch 7/10\n",
      "\u001b[1m10818/10818\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.7105e-09\n",
      "Epoch 8/10\n",
      "\u001b[1m10818/10818\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3767e-09\n",
      "Epoch 9/10\n",
      "\u001b[1m10818/10818\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3736e-09\n",
      "Epoch 10/10\n",
      "\u001b[1m10818/10818\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6439e-09\n",
      "\n",
      "Entrenando Skip-Gram: window=2, embed_dim=312\n",
      "Epoch 1/10\n",
      "\u001b[1m10818/10818\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 6ms/step - accuracy: 0.9848 - loss: 0.0236\n",
      "Epoch 2/10\n",
      "\u001b[1m10818/10818\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.2098e-08\n",
      "Epoch 3/10\n",
      "\u001b[1m10818/10818\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.7479e-08\n",
      "Epoch 4/10\n",
      "\u001b[1m10818/10818\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.8890e-09\n",
      "Epoch 5/10\n",
      "\u001b[1m10818/10818\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.1207e-09\n",
      "Epoch 6/10\n",
      "\u001b[1m10818/10818\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.5726e-09\n",
      "Epoch 7/10\n",
      "\u001b[1m10818/10818\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.6027e-09\n",
      "Epoch 8/10\n",
      "\u001b[1m10818/10818\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.8973e-09\n",
      "Epoch 9/10\n",
      "\u001b[1m10818/10818\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.3997e-09\n",
      "Epoch 10/10\n",
      "\u001b[1m10818/10818\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.0407e-09\n",
      "\n",
      "Entrenando Skip-Gram: window=2, embed_dim=752\n",
      "Epoch 1/10\n",
      "\u001b[1m10818/10818\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 18ms/step - accuracy: 0.9850 - loss: 0.0236\n",
      "Epoch 2/10\n",
      "\u001b[1m10818/10818\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 4.5228e-08\n",
      "Epoch 3/10\n",
      "\u001b[1m10441/10818\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 9.4233e-09"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 73\u001b[39m\n\u001b[32m     68\u001b[39m model = build_skipgram_model(vocab_size=vocab_size, \n\u001b[32m     69\u001b[39m                              embedding_dim=ed,\n\u001b[32m     70\u001b[39m                              learning_rate=\u001b[32m0.025\u001b[39m)\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# 2) entrenar\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_context\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# ajusta número de épocas\u001b[39;49;00m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     79\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# 3) guardar historia y modelo\u001b[39;00m\n\u001b[32m     82\u001b[39m histories[(w, ed)] = history\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jbarc\\Documents\\Deep learning\\UFVDeepLearning\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jbarc\\Documents\\Deep learning\\UFVDeepLearning\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jbarc\\Documents\\Deep learning\\UFVDeepLearning\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jbarc\\Documents\\Deep learning\\UFVDeepLearning\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jbarc\\Documents\\Deep learning\\UFVDeepLearning\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jbarc\\Documents\\Deep learning\\UFVDeepLearning\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jbarc\\Documents\\Deep learning\\UFVDeepLearning\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jbarc\\Documents\\Deep learning\\UFVDeepLearning\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jbarc\\Documents\\Deep learning\\UFVDeepLearning\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jbarc\\Documents\\Deep learning\\UFVDeepLearning\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jbarc\\Documents\\Deep learning\\UFVDeepLearning\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jbarc\\Documents\\Deep learning\\UFVDeepLearning\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dot, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_skipgram_model(vocab_size, \n",
    "                         embedding_dim, \n",
    "                         learning_rate=0.025,\n",
    "                         beta_1=0.9, \n",
    "                         beta_2=0.999):\n",
    "    \"\"\"\n",
    "    Devuelve un modelo Skip-Gram compilado que:\n",
    "     - Recibe dos inputs enteros (target y context, cada uno shape=())\n",
    "     - Usa una capa Embedding compartida de tamaño (vocab_size, embedding_dim)\n",
    "     - Calcula el dot-product y pasa por sigmoide\n",
    "     - Usa binary_crossentropy + Adam\n",
    "    \"\"\"\n",
    "    # 1) capas de entrada (índice único por ejemplo)\n",
    "    target_input  = Input(shape=(), dtype='int32', name='target_input')\n",
    "    context_input = Input(shape=(), dtype='int32', name='context_input')\n",
    "    \n",
    "    # 2) capa Embedding compartida\n",
    "    embed = Embedding(input_dim=vocab_size,\n",
    "                      output_dim=embedding_dim,\n",
    "                      input_length=1,\n",
    "                      name='shared_embedding',\n",
    "                      embeddings_initializer='glorot_uniform',\n",
    "                      trainable=True)\n",
    "    \n",
    "    # 3) obtenemos los vectores embebidos y aplanamos\n",
    "    target_vec  = Reshape((embedding_dim,)) (embed(target_input))\n",
    "    context_vec = Reshape((embedding_dim,)) (embed(context_input))\n",
    "    \n",
    "    # 4) puntuación = dot-product\n",
    "    dot_prod = Dot(axes=1, normalize=False, name='dot_product')(\n",
    "        [target_vec, context_vec]\n",
    "    )\n",
    "    \n",
    "    # 5) salida sigmoide para predecir par positivo/negativo\n",
    "    output = Reshape((1,))(dot_prod)\n",
    "    output = tf.keras.activations.sigmoid(output)\n",
    "    \n",
    "    # 6) construir y compilar modelo\n",
    "    model = Model(inputs=[target_input, context_input], outputs=output, name=f\"skipgram_{embedding_dim}\")\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Ejemplo de entrenamiento de los 6 modelos (3 dims × 2 ventanas)\n",
    "# --------------------------------------------------------------\n",
    "embedding_dims = [45, 312, 752]\n",
    "window_sizes   = [2, 4]\n",
    "histories      = {}\n",
    "\n",
    "for w in window_sizes:\n",
    "    X_target, X_context = datasets[w]['X_train']\n",
    "    y_train             = datasets[w]['y_train']\n",
    "    \n",
    "    for ed in embedding_dims:\n",
    "        print(f\"\\nEntrenando Skip-Gram: window={w}, embed_dim={ed}\")\n",
    "        \n",
    "        # 1) construir\n",
    "        model = build_skipgram_model(vocab_size=vocab_size, \n",
    "                                     embedding_dim=ed,\n",
    "                                     learning_rate=0.025)\n",
    "        \n",
    "        # 2) entrenar\n",
    "        history = model.fit(\n",
    "            x=[X_target, X_context],\n",
    "            y=y_train,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            epochs=10,                # ajusta número de épocas\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # 3) guardar historia y modelo\n",
    "        histories[(w, ed)] = history\n",
    "\n",
    "# Ahora `histories[(w,ed)].history['loss']` contiene la curva de pérdida\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94daa88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
