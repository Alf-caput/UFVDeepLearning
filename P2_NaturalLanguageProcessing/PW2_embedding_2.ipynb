{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c968420",
   "metadata": {},
   "source": [
    "# Practica 2 - Natural Language processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "61a5800b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population -2020</th>\n",
       "      <th>Land Area (Kmï¿½)</th>\n",
       "      <th>Density (P/Kmï¿½)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cb774db0d1</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928346</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549e992a42</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2877797</td>\n",
       "      <td>27400.0</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>088c60f138</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>43851044</td>\n",
       "      <td>2381740.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9642c003ef</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>77265</td>\n",
       "      <td>470.0</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358bd9e861</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Angola</td>\n",
       "      <td>32866272</td>\n",
       "      <td>1246700.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         text  \\\n",
       "textID                                                          \n",
       "cb774db0d1                I`d have responded, if I were going   \n",
       "549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "088c60f138                          my boss is bullying me...   \n",
       "9642c003ef                     what interview! leave me alone   \n",
       "358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                                  selected_text sentiment Time of Tweet  \\\n",
       "textID                                                                    \n",
       "cb774db0d1  I`d have responded, if I were going   neutral       morning   \n",
       "549e992a42                             Sooo SAD  negative          noon   \n",
       "088c60f138                          bullying me  negative         night   \n",
       "9642c003ef                       leave me alone  negative       morning   \n",
       "358bd9e861                        Sons of ****,  negative          noon   \n",
       "\n",
       "           Age of User      Country  Population -2020  Land Area (Kmï¿½)  \\\n",
       "textID                                                                     \n",
       "cb774db0d1        0-20  Afghanistan          38928346           652860.0   \n",
       "549e992a42       21-30      Albania           2877797            27400.0   \n",
       "088c60f138       31-45      Algeria          43851044          2381740.0   \n",
       "9642c003ef       46-60      Andorra             77265              470.0   \n",
       "358bd9e861       60-70       Angola          32866272          1246700.0   \n",
       "\n",
       "            Density (P/Kmï¿½)  \n",
       "textID                         \n",
       "cb774db0d1                 60  \n",
       "549e992a42                105  \n",
       "088c60f138                 18  \n",
       "9642c003ef                164  \n",
       "358bd9e861                 26  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = \"data\"\n",
    "train_path = os.path.join(data_dir, \"train.csv\")\n",
    "test_path = os.path.join(data_dir, \"test.csv\")\n",
    "df_train = pd.read_csv(train_path, encoding='ISO-8859-1', index_col=\"textID\")\n",
    "df_test = pd.read_csv(test_path, encoding='ISO-8859-1', index_col=\"textID\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cb143141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                 1\n",
       "selected_text        1\n",
       "sentiment            0\n",
       "Time of Tweet        0\n",
       "Age of User          0\n",
       "Country              0\n",
       "Population -2020     0\n",
       "Land Area (Kmï¿½)    0\n",
       "Density (P/Kmï¿½)    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "629162a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                1281\n",
       "sentiment           1281\n",
       "Time of Tweet       1281\n",
       "Age of User         1281\n",
       "Country             1281\n",
       "Population -2020    1281\n",
       "Land Area (Km²)     1281\n",
       "Density (P/Km²)     1281\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "73e14886",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna()\n",
    "df_test = df_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ec4e660d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"text\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b8a6ad5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(27480, 33), dtype=int64, numpy=\n",
       "array([[  293,    17, 15185, ...,     0,     0,     0],\n",
       "       [  413,   115,     2, ...,     0,     0,     0],\n",
       "       [    6,  1335,    10, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  225,    31,    12, ...,     0,     0,     0],\n",
       "       [   20,     9,    28, ...,     0,     0,     0],\n",
       "       [   29,    30,  6480, ...,     0,     0,     0]])>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    output_mode='int',\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    split=\"whitespace\",\n",
    ")\n",
    "\n",
    "corpus = df_train[\"text\"].values\n",
    "\n",
    "vectorize_layer.adapt(corpus)\n",
    "\n",
    "vectorized_train = vectorize_layer(corpus)\n",
    "vectorized_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "29037a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " np.str_('i'),\n",
       " np.str_('to'),\n",
       " np.str_('the'),\n",
       " np.str_('a'),\n",
       " np.str_('my'),\n",
       " np.str_('and'),\n",
       " np.str_('you'),\n",
       " np.str_('it')]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "37920279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15185,    17], dtype=int32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import skipgrams\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(vectorized_train)\n",
    "\n",
    "vocab_size = len(vectorize_layer.get_vocabulary())\n",
    "window_size = 3\n",
    "\n",
    "def tf_skipgrams(sequence):\n",
    "    sequence = tf.cast(sequence, tf.int32)\n",
    "    \n",
    "    def generate_pairs(x):\n",
    "        pairs, _ = skipgrams(\n",
    "            x.numpy(),\n",
    "            vocabulary_size=vocab_size,\n",
    "            window_size=window_size,\n",
    "            negative_samples=0  # set to >0 if you want (target, context), label\n",
    "        )\n",
    "        if not pairs:\n",
    "            # Return dummy data if skipgrams returns empty\n",
    "            return tf.zeros((0, 2), dtype=tf.int32)\n",
    "        return tf.convert_to_tensor(pairs, dtype=tf.int32)\n",
    "\n",
    "    pairs_tensor = tf.py_function(func=generate_pairs, inp=[sequence], Tout=tf.int32)\n",
    "    pairs_tensor.set_shape([None, 2])\n",
    "    return tf.data.Dataset.from_tensor_slices(pairs_tensor)\n",
    "\n",
    "train_ds = train_ds.flat_map(tf_skipgrams)\n",
    "\n",
    "next(train_ds.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "93618d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(2,), dtype=tf.int32, name=None)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6b95863f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = (\n",
    "    train_ds\n",
    "    .map(lambda x: (tf.one_hot(x[0], depth=vocab_size), tf.one_hot(x[1], depth=vocab_size)))\n",
    ")\n",
    "next(train_ds.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0239e456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(29164,), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(29164,), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b2f34036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ keras_tensor_24CLO… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ keras_tensor_24C… │\n",
       "│                     │                   │            │ keras_tensor_24C… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dot_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ keras_tensor_24CLO… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot_2 (\u001b[38;5;33mDot\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ keras_tensor_24C… │\n",
       "│                     │                   │            │ keras_tensor_24C… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ dot_2[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m2\u001b[0m │ reshape_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (8.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2\u001b[0m (8.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (8.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2\u001b[0m (8.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import Model, Input, layers\n",
    "from tensorflow import keras\n",
    "\n",
    "embedding_dim = 128\n",
    "\n",
    "# Inputs are integer word indices\n",
    "input_target = tf.keras.Input(shape=(), dtype=tf.int32)\n",
    "input_context = tf.keras.Input(shape=(), dtype=tf.int32)\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)\n",
    "\n",
    "target_embed = embedding(input_target)\n",
    "context_embed = embedding(input_context)\n",
    "\n",
    "# Dot product\n",
    "dot_product = tf.keras.layers.Dot(axes=-1)([target_embed, context_embed])\n",
    "# We reshape to 1 to get the decoy.\n",
    "dot_product = layers.Reshape((1,))(dot_product)\n",
    "\n",
    "# We define the output layer\n",
    "output = layers.Dense(\n",
    "    1,\n",
    "    activation = 'sigmoid')(dot_product)\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    inputs = [target_embed, context_embed],\n",
    "    outputs = output)\n",
    "\n",
    "model.compile(\n",
    "    loss = 'binary_crossentropy',\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 0.025,\n",
    "                                             beta_1 = 0.9,\n",
    "                                             beta_2 = 0.999),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69b9c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43565b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the TF Board callback\n",
    "import numpy as np \n",
    "\n",
    "y_train = np.ones(len(X_target))\n",
    "# Training process execution\n",
    "# Epochs: 1\n",
    "# Number of validation steps: 10\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs = 25,\n",
    "    batch_size = 64,\n",
    "    callbacks = [tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64106bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model, Input, layers\n",
    "from tensorflow.keras.layers import Embedding, Dot, Reshape, Dense\n",
    "\n",
    "embedding_dim = 64\n",
    "\n",
    "# We dimulate an embedding layer using a Dense layer\n",
    "shared_embedding_layer = layers.Dense(\n",
    "    embedding_dim,\n",
    "    use_bias = False,\n",
    "    name = 'embedding_dense')\n",
    "\n",
    "# Define input layer, one for each element in the pairs.\n",
    "target_input = Input(\n",
    "    shape = (vocab_size,),\n",
    "    name = 'target_onehot')\n",
    "\n",
    "context_input = Input(\n",
    "    shape = (vocab_size,),\n",
    "    name = 'context_onehot')\n",
    "\n",
    "# We apply the embedding layer to both inputs\n",
    "target_vector = shared_embedding_layer(target_input)\n",
    "context_vector = shared_embedding_layer(context_input)\n",
    "\n",
    "# We combine both inputs using a Cosine/dot product similarity.\n",
    "dot_product = layers.Dot(axes=-1)([target_vector, context_vector])\n",
    "# We reshape to 1 to get the decoy.\n",
    "dot_product = layers.Reshape((1,))(dot_product)\n",
    "\n",
    "# We define the output layer\n",
    "output = layers.Dense(\n",
    "    1,\n",
    "    activation = 'sigmoid')(dot_product)\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    inputs = [target_input, context_input],\n",
    "    outputs = output)\n",
    "\n",
    "model.compile(\n",
    "    loss = 'binary_crossentropy',\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 0.025,\n",
    "                                             beta_1 = 0.9,\n",
    "                                             beta_2 = 0.999),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
