{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c968420",
   "metadata": {},
   "source": [
    "# Practica 2 - Natural Language processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61a5800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras import Model, Input, layers\n",
    "from tensorflow.keras.layers import Embedding, Dot, Reshape, Dense, TextVectorization\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import skipgrams\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "229db632",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(\"data\", \"train.csv\"), sep=',', header=0, encoding='ISO-8859-1', index_col=\"textID\")\n",
    "df_test = pd.read_csv(os.path.join(\"data\", \"test.csv\"), sep=',', header=0, encoding='ISO-8859-1', index_col=\"textID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0108cf",
   "metadata": {},
   "source": [
    "Comprobamos si hay NAs en el dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "577290a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                1\n",
       "selected_text       1\n",
       "sentiment           0\n",
       "Time of Tweet       0\n",
       "Age of User         0\n",
       "Country             0\n",
       "Population -2020    0\n",
       "Land Area (Km²)     0\n",
       "Density (P/Km²)     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8746b5b",
   "metadata": {},
   "source": [
    "Podemos observar que hay uno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1337e5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population -2020</th>\n",
       "      <th>Land Area (Km²)</th>\n",
       "      <th>Density (P/Km²)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fdb77c3752</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Namibia</td>\n",
       "      <td>2540905</td>\n",
       "      <td>823000.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text selected_text sentiment Time of Tweet Age of User  Country  \\\n",
       "textID                                                                       \n",
       "fdb77c3752  NaN           NaN   neutral         night       31-45  Namibia   \n",
       "\n",
       "            Population -2020  Land Area (Km²)  Density (P/Km²)  \n",
       "textID                                                          \n",
       "fdb77c3752           2540905         823000.0                3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train.isna().any(axis = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24f4069c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                0\n",
       "selected_text       0\n",
       "sentiment           0\n",
       "Time of Tweet       0\n",
       "Age of User         0\n",
       "Country             0\n",
       "Population -2020    0\n",
       "Land Area (Km²)     0\n",
       "Density (P/Km²)     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.dropna()\n",
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb5d7ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                1281\n",
       "sentiment           1281\n",
       "Time of Tweet       1281\n",
       "Age of User         1281\n",
       "Country             1281\n",
       "Population -2020    1281\n",
       "Land Area (Km²)     1281\n",
       "Density (P/Km²)     1281\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef7979f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population -2020</th>\n",
       "      <th>Land Area (Km²)</th>\n",
       "      <th>Density (P/Km²)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text sentiment Time of Tweet Age of User Country  Population -2020  \\\n",
       "textID                                                                      \n",
       "NaN     NaN       NaN           NaN         NaN     NaN               NaN   \n",
       "NaN     NaN       NaN           NaN         NaN     NaN               NaN   \n",
       "NaN     NaN       NaN           NaN         NaN     NaN               NaN   \n",
       "NaN     NaN       NaN           NaN         NaN     NaN               NaN   \n",
       "NaN     NaN       NaN           NaN         NaN     NaN               NaN   \n",
       "\n",
       "        Land Area (Km²)  Density (P/Km²)  \n",
       "textID                                    \n",
       "NaN                 NaN              NaN  \n",
       "NaN                 NaN              NaN  \n",
       "NaN                 NaN              NaN  \n",
       "NaN                 NaN              NaN  \n",
       "NaN                 NaN              NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test.isna().any(axis = 1)].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a063194e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                0\n",
       "sentiment           0\n",
       "Time of Tweet       0\n",
       "Age of User         0\n",
       "Country             0\n",
       "Population -2020    0\n",
       "Land Area (Km²)     0\n",
       "Density (P/Km²)     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test.dropna()\n",
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca7b34ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df_train['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed4d84dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer = TextVectorization(\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    split=\"whitespace\",\n",
    "    output_mode='int'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc298af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer.adapt(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b0de3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_train = vectorize_layer(df_train[\"text\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56b84f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(27480, 33), dtype=int64, numpy=\n",
       "array([[  293,    17, 15185, ...,     0,     0,     0],\n",
       "       [  413,   115,     2, ...,     0,     0,     0],\n",
       "       [    6,  1335,    10, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  225,    31,    12, ...,     0,     0,     0],\n",
       "       [   20,     9,    28, ...,     0,     0,     0],\n",
       "       [   29,    30,  6480, ...,     0,     0,     0]])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3757eb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4fb2193",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_index = {word: idx for idx, word in enumerate(vocab)}\n",
    "index_to_token = {idx: word for idx, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a9b76afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ds = tf.data.Dataset.from_tensor_slices(df_train[\"text\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8331ea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_ds = text_ds.map(lambda x: vectorize_layer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e771f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vectorize_layer.get_vocabulary()\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "def tf_skipgrams(sequence):\n",
    "    sequence = sequence.numpy()\n",
    "    couples, labels = skipgrams(\n",
    "        sequence=sequence,\n",
    "        vocabulary_size=vocab_size,\n",
    "        window_size=4,\n",
    "    )\n",
    "    if len(couples) == 0:\n",
    "        return (tf.constant([[0, 0]], dtype=tf.int32), tf.constant([0], dtype=tf.int32))\n",
    "    return (tf.constant(couples, dtype=tf.int32), tf.constant(labels, dtype=tf.int32))\n",
    "\n",
    "def tf_skipgrams_wrapper(sequence):\n",
    "    couples, labels = tf.py_function(tf_skipgrams, [sequence], [tf.int32, tf.int32])\n",
    "    couples.set_shape([None, 2])\n",
    "    labels.set_shape([None])\n",
    "    return couples, labels\n",
    "\n",
    "skipgram_ds = vectorized_ds.map(tf_skipgrams_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09259daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population -2020</th>\n",
       "      <th>Land Area (Kmï¿½)</th>\n",
       "      <th>Density (P/Kmï¿½)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cb774db0d1</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928346</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549e992a42</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2877797</td>\n",
       "      <td>27400.0</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>088c60f138</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>43851044</td>\n",
       "      <td>2381740.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9642c003ef</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>77265</td>\n",
       "      <td>470.0</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358bd9e861</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Angola</td>\n",
       "      <td>32866272</td>\n",
       "      <td>1246700.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         text  \\\n",
       "textID                                                          \n",
       "cb774db0d1                I`d have responded, if I were going   \n",
       "549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "088c60f138                          my boss is bullying me...   \n",
       "9642c003ef                     what interview! leave me alone   \n",
       "358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                                  selected_text sentiment Time of Tweet  \\\n",
       "textID                                                                    \n",
       "cb774db0d1  I`d have responded, if I were going   neutral       morning   \n",
       "549e992a42                             Sooo SAD  negative          noon   \n",
       "088c60f138                          bullying me  negative         night   \n",
       "9642c003ef                       leave me alone  negative       morning   \n",
       "358bd9e861                        Sons of ****,  negative          noon   \n",
       "\n",
       "           Age of User      Country  Population -2020  Land Area (Kmï¿½)  \\\n",
       "textID                                                                     \n",
       "cb774db0d1        0-20  Afghanistan          38928346           652860.0   \n",
       "549e992a42       21-30      Albania           2877797            27400.0   \n",
       "088c60f138       31-45      Algeria          43851044          2381740.0   \n",
       "9642c003ef       46-60      Andorra             77265              470.0   \n",
       "358bd9e861       60-70       Angola          32866272          1246700.0   \n",
       "\n",
       "            Density (P/Kmï¿½)  \n",
       "textID                         \n",
       "cb774db0d1                 60  \n",
       "549e992a42                105  \n",
       "088c60f138                 18  \n",
       "9642c003ef                164  \n",
       "358bd9e861                 26  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = \"data\"\n",
    "train_path = os.path.join(data_dir, \"train.csv\")\n",
    "test_path = os.path.join(data_dir, \"test.csv\")\n",
    "df_train = pd.read_csv(train_path, encoding='ISO-8859-1', index_col=\"textID\")\n",
    "df_test = pd.read_csv(test_path, encoding='ISO-8859-1', index_col=\"textID\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb143141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                 1\n",
       "selected_text        1\n",
       "sentiment            0\n",
       "Time of Tweet        0\n",
       "Age of User          0\n",
       "Country              0\n",
       "Population -2020     0\n",
       "Land Area (Kmï¿½)    0\n",
       "Density (P/Kmï¿½)    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "629162a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                1281\n",
       "sentiment           1281\n",
       "Time of Tweet       1281\n",
       "Age of User         1281\n",
       "Country             1281\n",
       "Population -2020    1281\n",
       "Land Area (Km²)     1281\n",
       "Density (P/Km²)     1281\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73e14886",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna()\n",
    "df_test = df_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec4e660d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"text\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8a6ad5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(27480, 33), dtype=int64, numpy=\n",
       "array([[  293,    17, 15185, ...,     0,     0,     0],\n",
       "       [  413,   115,     2, ...,     0,     0,     0],\n",
       "       [    6,  1335,    10, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  225,    31,    12, ...,     0,     0,     0],\n",
       "       [   20,     9,    28, ...,     0,     0,     0],\n",
       "       [   29,    30,  6480, ...,     0,     0,     0]])>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    output_mode='int',\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    split=\"whitespace\",\n",
    ")\n",
    "\n",
    "corpus = df_train[\"text\"].values\n",
    "\n",
    "vectorize_layer.adapt(corpus)\n",
    "\n",
    "vectorized_train = vectorize_layer(corpus)\n",
    "vectorized_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "29037a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " np.str_('i'),\n",
       " np.str_('to'),\n",
       " np.str_('the'),\n",
       " np.str_('a'),\n",
       " np.str_('my'),\n",
       " np.str_('and'),\n",
       " np.str_('you'),\n",
       " np.str_('it')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "37920279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([69, 47], dtype=int32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import skipgrams\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(vectorized_train)\n",
    "\n",
    "vocab_size = len(vectorize_layer.get_vocabulary())\n",
    "window_size = 3\n",
    "\n",
    "def tf_skipgrams(sequence):\n",
    "    sequence = tf.cast(sequence, tf.int32)\n",
    "    \n",
    "    def generate_pairs(x):\n",
    "        pairs, _ = skipgrams(\n",
    "            x.numpy(),\n",
    "            vocabulary_size=vocab_size,\n",
    "            window_size=window_size,\n",
    "            negative_samples=0  # set to >0 if you want (target, context), label\n",
    "        )\n",
    "        if not pairs:\n",
    "            # Return dummy data if skipgrams returns empty\n",
    "            return tf.zeros((0, 2), dtype=tf.int32)\n",
    "        return tf.convert_to_tensor(pairs, dtype=tf.int32)\n",
    "\n",
    "    pairs_tensor = tf.py_function(func=generate_pairs, inp=[sequence], Tout=tf.int32)\n",
    "    return tf.data.Dataset.from_tensor_slices(pairs_tensor)\n",
    "\n",
    "# Use flat_map to flatten pairs\n",
    "train_ds = train_ds.flat_map(tf_skipgrams)\n",
    "\n",
    "# Shuffle and batch\n",
    "next(train_ds.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6b95863f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 1., ..., 0., 0., 0.], dtype=float32),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = (\n",
    "    train_ds\n",
    "    .map(lambda x: (tf.one_hot(x[0], depth=vocab_size), tf.one_hot(x[1], depth=vocab_size)))\n",
    ")\n",
    "next(train_ds.as_numpy_iterator())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
