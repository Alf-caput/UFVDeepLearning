{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5c968420",
      "metadata": {
        "id": "5c968420"
      },
      "source": [
        "# Practica 2 - Natural Language processing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qewyVvQ32m1M",
        "outputId": "797e0fe2-3b31-4d79-b31c-827e06d1aff4"
      },
      "id": "qewyVvQ32m1M",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras import Model, Input, layers\n",
        "from tensorflow.keras.layers import Embedding, Dot, Reshape, Dense\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import skipgrams\n",
        "\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "import re\n",
        "from collections import Counter\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import skipgrams"
      ],
      "metadata": {
        "id": "9sme3605sBSj"
      },
      "id": "9sme3605sBSj",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import os\n",
        "\n",
        "# Crear el directorio de datos si no existe\n",
        "data_dir = \"data\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir)\n",
        "\n",
        "# URL de Google Drive en formato correcto para gdown\n",
        "url = \"https://drive.google.com/uc?id=1GXSUzaXDvrlcimgTwRR9tmDr6xr8gu49\"\n",
        "zip_filename = \"sentiment_analysis.zip\"\n",
        "zip_path = os.path.join(data_dir, zip_filename)\n",
        "\n",
        "# Descargar el archivo\n",
        "if not os.path.exists(zip_path):\n",
        "    gdown.download(url, zip_path, quiet=False)\n",
        "else:\n",
        "    print(\"Data zipfile already exists\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3HonUdDiquT",
        "outputId": "dc44d3b0-1c0a-4a5c-da10-856f4ed7c070"
      },
      "id": "C3HonUdDiquT",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data zipfile already exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "data_dir = \"data\"\n",
        "zip_filename = \"sentiment_analysis.zip\"\n",
        "zip_path = os.path.join(data_dir, zip_filename)\n",
        "files = [\"train.csv\", \"test.csv\"]\n",
        "full_paths = [os.path.join(data_dir, file) for file in files]\n",
        "\n",
        "if not all(os.path.isfile(path) for path in full_paths):\n",
        "    with ZipFile(zip_path, 'r') as zf:\n",
        "        with ThreadPoolExecutor() as exe:\n",
        "            for file in zf.namelist():\n",
        "                if not file.startswith(\"__MACOSX\"):\n",
        "                    exe.submit(zf.extract, file, path=data_dir)\n",
        "else:\n",
        "    print(\"test and train files already exist\")"
      ],
      "metadata": {
        "id": "fBNIbhvSmW-C"
      },
      "id": "fBNIbhvSmW-C",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "61a5800b",
      "metadata": {
        "id": "61a5800b",
        "outputId": "68f07270-88ae-4703-9635-d88092872828",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                         text  \\\n",
              "textID                                                          \n",
              "cb774db0d1                I`d have responded, if I were going   \n",
              "549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
              "088c60f138                          my boss is bullying me...   \n",
              "9642c003ef                     what interview! leave me alone   \n",
              "358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
              "\n",
              "                                  selected_text sentiment Time of Tweet  \\\n",
              "textID                                                                    \n",
              "cb774db0d1  I`d have responded, if I were going   neutral       morning   \n",
              "549e992a42                             Sooo SAD  negative          noon   \n",
              "088c60f138                          bullying me  negative         night   \n",
              "9642c003ef                       leave me alone  negative       morning   \n",
              "358bd9e861                        Sons of ****,  negative          noon   \n",
              "\n",
              "           Age of User      Country  Population -2020  Land Area (Km²)  \\\n",
              "textID                                                                   \n",
              "cb774db0d1        0-20  Afghanistan          38928346         652860.0   \n",
              "549e992a42       21-30      Albania           2877797          27400.0   \n",
              "088c60f138       31-45      Algeria          43851044        2381740.0   \n",
              "9642c003ef       46-60      Andorra             77265            470.0   \n",
              "358bd9e861       60-70       Angola          32866272        1246700.0   \n",
              "\n",
              "            Density (P/Km²)  \n",
              "textID                       \n",
              "cb774db0d1               60  \n",
              "549e992a42              105  \n",
              "088c60f138               18  \n",
              "9642c003ef              164  \n",
              "358bd9e861               26  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9339e2bd-6f66-46e5-becf-1c5d04d7e86a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Time of Tweet</th>\n",
              "      <th>Age of User</th>\n",
              "      <th>Country</th>\n",
              "      <th>Population -2020</th>\n",
              "      <th>Land Area (Km²)</th>\n",
              "      <th>Density (P/Km²)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>textID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>cb774db0d1</th>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "      <td>morning</td>\n",
              "      <td>0-20</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>38928346</td>\n",
              "      <td>652860.0</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>549e992a42</th>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "      <td>noon</td>\n",
              "      <td>21-30</td>\n",
              "      <td>Albania</td>\n",
              "      <td>2877797</td>\n",
              "      <td>27400.0</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>088c60f138</th>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "      <td>night</td>\n",
              "      <td>31-45</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>43851044</td>\n",
              "      <td>2381740.0</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9642c003ef</th>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "      <td>morning</td>\n",
              "      <td>46-60</td>\n",
              "      <td>Andorra</td>\n",
              "      <td>77265</td>\n",
              "      <td>470.0</td>\n",
              "      <td>164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>358bd9e861</th>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "      <td>noon</td>\n",
              "      <td>60-70</td>\n",
              "      <td>Angola</td>\n",
              "      <td>32866272</td>\n",
              "      <td>1246700.0</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9339e2bd-6f66-46e5-becf-1c5d04d7e86a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9339e2bd-6f66-46e5-becf-1c5d04d7e86a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9339e2bd-6f66-46e5-becf-1c5d04d7e86a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0514d991-bbd7-4e4c-a8c0-78c638ddb54a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0514d991-bbd7-4e4c-a8c0-78c638ddb54a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0514d991-bbd7-4e4c-a8c0-78c638ddb54a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 27481,\n  \"fields\": [\n    {\n      \"column\": \"textID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27481,\n        \"samples\": [\n          \"a7f72a928a\",\n          \"ef42dee96c\",\n          \"07d17131b1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27480,\n        \"samples\": [\n          \" Enjoy! Family trumps everything\",\n          \" --of them kinda turns me off of it all.  And then I buy more of them and dig a deeper hole, etc. ;;\",\n          \"Clive it`s my birthday pat me  http://apps.facebook.com/dogbook/profile/view/6386106\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"selected_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22430,\n        \"samples\": [\n          \"that is why I drive a (teeny tiny) honda civic\",\n          \"Sorry...but, I bet they aren`t that bad...\",\n          \"yummy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"neutral\",\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Time of Tweet\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"morning\",\n          \"noon\",\n          \"night\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age of User\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"0-20\",\n          \"21-30\",\n          \"70-100\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 195,\n        \"samples\": [\n          \"Philippines\",\n          \"Belgium\",\n          \"Sierra Leone\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Population -2020\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 150494590,\n        \"min\": 801,\n        \"max\": 1439323776,\n        \"num_unique_values\": 195,\n        \"samples\": [\n          109581078,\n          11589623,\n          7976983\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Land Area (Km\\u00b2)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1807424.6900064738,\n        \"min\": 0.0,\n        \"max\": 16376870.0,\n        \"num_unique_values\": 193,\n        \"samples\": [\n          2267050.0,\n          1280000.0,\n          100250.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Density (P/Km\\u00b2)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2013,\n        \"min\": 2,\n        \"max\": 26337,\n        \"num_unique_values\": 136,\n        \"samples\": [\n          400,\n          71,\n          331\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "data_dir = \"data\"\n",
        "train_path = os.path.join(data_dir, \"train.csv\")\n",
        "test_path = os.path.join(data_dir, \"test.csv\")\n",
        "train_df = pd.read_csv(train_path, encoding='ISO-8859-1', index_col=\"textID\")\n",
        "test_df = pd.read_csv(test_path, encoding='ISO-8859-1', index_col=\"textID\")\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.dropna()\n",
        "test_df = test_df.dropna()\n",
        "text_df = pd.concat([train_df, test_df])\n",
        "text_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq0r0Gzm4Voe",
        "outputId": "62f514f4-578d-4a50-d087-c27d540904b9"
      },
      "id": "Eq0r0Gzm4Voe",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31014, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b8a6ad5f",
      "metadata": {
        "id": "b8a6ad5f",
        "outputId": "6e8bd57d-0ee1-4f9d-9bdc-8dca688e55bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(31014, 33), dtype=int64, numpy=\n",
              "array([[284,  17,   1, ...,   0,   0,   0],\n",
              "       [416, 112,   2, ...,   0,   0,   0],\n",
              "       [  6,   1,  10, ...,   0,   0,   0],\n",
              "       ...,\n",
              "       [  2,  54,  57, ...,   0,   0,   0],\n",
              "       [  1,  57,  10, ...,   0,   0,   0],\n",
              "       [  1,   1,   1, ...,   0,   0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "vocab_size = 1_000\n",
        "\n",
        "vectorize_layer = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    standardize=\"lower_and_strip_punctuation\",\n",
        "    split=\"whitespace\",\n",
        ")\n",
        "\n",
        "corpus = text_df[\"text\"].values\n",
        "\n",
        "vectorize_layer.adapt(corpus)\n",
        "\n",
        "vectorize_layer(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "29037a2f",
      "metadata": {
        "id": "29037a2f",
        "outputId": "2780c785-debf-48d7-f3c9-1bea50022920",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " np.str_('i'),\n",
              " np.str_('to'),\n",
              " np.str_('the'),\n",
              " np.str_('a'),\n",
              " np.str_('my'),\n",
              " np.str_('and'),\n",
              " np.str_('you'),\n",
              " np.str_('it')]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "vectorize_layer.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(train_df[\"text\"])\n",
        "\n",
        "print(text_ds.element_spec)\n",
        "for sentence in text_ds.take(5):\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VRzmr9wSPb0",
        "outputId": "9e79b720-5000-4218-ae2e-023d5cb63240"
      },
      "id": "_VRzmr9wSPb0",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorSpec(shape=(), dtype=tf.string, name=None)\n",
            "tf.Tensor(b' I`d have responded, if I were going', shape=(), dtype=string)\n",
            "tf.Tensor(b' Sooo SAD I will miss you here in San Diego!!!', shape=(), dtype=string)\n",
            "tf.Tensor(b'my boss is bullying me...', shape=(), dtype=string)\n",
            "tf.Tensor(b' what interview! leave me alone', shape=(), dtype=string)\n",
            "tf.Tensor(b' Sons of ****, why couldn`t they put them on the releases we already bought', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the vectorization layer to get token sequences\n",
        "vectorized_ds = text_ds.map(lambda x: vectorize_layer(x))\n",
        "\n",
        "print(vectorized_ds.element_spec)\n",
        "next(vectorized_ds.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJraTh4yE83Y",
        "outputId": "b9586301-67e4-42ac-8011-8aada81a6375"
      },
      "id": "EJraTh4yE83Y",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorSpec(shape=(None,), dtype=tf.int64, name=None)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([284,  17,   1,  68,   2, 121,  47])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_skipgram_pairs(sequence, window_size=4):\n",
        "    seq_len = tf.shape(sequence)[0]\n",
        "    positions = tf.range(seq_len)\n",
        "\n",
        "    def extract_context(i):\n",
        "        target = sequence[i]\n",
        "        return tf.cond(\n",
        "            tf.equal(target, 0),\n",
        "            lambda: tf.data.Dataset.from_tensors((tf.constant(-1, dtype=sequence.dtype),\n",
        "                                                  tf.constant(-1, dtype=sequence.dtype))).take(0),\n",
        "            lambda: _valid_context(i, target)\n",
        "        )\n",
        "\n",
        "    def _valid_context(i, target):\n",
        "        start = tf.maximum(0, i - window_size)\n",
        "        end = tf.minimum(seq_len, i + window_size + 1)\n",
        "\n",
        "        # Exclude center word\n",
        "        left = sequence[start:i]\n",
        "        right = sequence[i + 1:end]\n",
        "        context = tf.concat([left, right], axis=0)\n",
        "\n",
        "        # Remove zeros\n",
        "        non_zero = tf.not_equal(context, 0)\n",
        "        context = tf.boolean_mask(context, non_zero)\n",
        "        targets = tf.fill([tf.shape(context)[0]], target)\n",
        "\n",
        "        return tf.data.Dataset.from_tensor_slices((targets, context))\n",
        "\n",
        "    return tf.data.Dataset.from_tensor_slices(positions).flat_map(extract_context)\n",
        "\n",
        "# Apply skipgram generation to each vectorized sentence\n",
        "sg_ds = vectorized_ds.flat_map(lambda x: generate_skipgram_pairs(x, window_size=4))\n",
        "\n",
        "# Optionally convert to list of tuples\n",
        "print(sg_ds.element_spec)\n",
        "next(sg_ds.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTiOtnJcFWlJ",
        "outputId": "cda7e89e-d228-4257-f4ba-20e28e7cf930"
      },
      "id": "yTiOtnJcFWlJ",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.int64(284), np.int64(17))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for target_idx, context_idx in sg_ds.take(20):\n",
        "  print(f\"target: {vectorize_layer.get_vocabulary()[target_idx]} | context: {vectorize_layer.get_vocabulary()[context_idx]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hURVd-JIFmbQ",
        "outputId": "2ce7ddd6-a370-4813-b798-e15a432c2a55"
      },
      "id": "hURVd-JIFmbQ",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target: id | context: have\n",
            "target: id | context: [UNK]\n",
            "target: id | context: if\n",
            "target: id | context: i\n",
            "target: have | context: id\n",
            "target: have | context: [UNK]\n",
            "target: have | context: if\n",
            "target: have | context: i\n",
            "target: have | context: were\n",
            "target: [UNK] | context: id\n",
            "target: [UNK] | context: have\n",
            "target: [UNK] | context: if\n",
            "target: [UNK] | context: i\n",
            "target: [UNK] | context: were\n",
            "target: [UNK] | context: going\n",
            "target: if | context: id\n",
            "target: if | context: have\n",
            "target: if | context: [UNK]\n",
            "target: if | context: i\n",
            "target: if | context: were\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(train_df[\"text\"])\n",
        "\n",
        "print(train_ds.element_spec)\n",
        "for sentence in train_ds.take(5):\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7aQqkOvSXSZ",
        "outputId": "9f480f62-b356-42b4-b14d-9fcd7c200481"
      },
      "id": "U7aQqkOvSXSZ",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorSpec(shape=(), dtype=tf.string, name=None)\n",
            "tf.Tensor(b' I`d have responded, if I were going', shape=(), dtype=string)\n",
            "tf.Tensor(b' Sooo SAD I will miss you here in San Diego!!!', shape=(), dtype=string)\n",
            "tf.Tensor(b'my boss is bullying me...', shape=(), dtype=string)\n",
            "tf.Tensor(b' what interview! leave me alone', shape=(), dtype=string)\n",
            "tf.Tensor(b' Sons of ****, why couldn`t they put them on the releases we already bought', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices(train_df[\"text\"])\n",
        "\n",
        "train_ds = (\n",
        "    train_ds\n",
        "    .map(\n",
        "        lambda x: vectorize_layer(x),\n",
        "        num_parallel_calls=tf.data.AUTOTUNE,\n",
        "    )\n",
        "    .flat_map(\n",
        "        lambda x: generate_skipgram_pairs(x, window_size=2),\n",
        "    )\n",
        "    # .cache()\n",
        "    # .map(\n",
        "    #     lambda x, y: ((x, y), tf.constant(1)),\n",
        "    #     num_parallel_calls=tf.data.AUTOTUNE,\n",
        "    # )\n",
        ")\n",
        "\n",
        "# lambda x: ((tf.one_hot(x[0], depth=vocab_size), tf.one_hot(x[1], depth=vocab_size)), tf.constant(1.0)),\n",
        "\n",
        "print(train_ds.element_spec)\n",
        "next(train_ds.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uYbFkAoQxZf",
        "outputId": "caa4835f-417d-446c-f012-52e1b80869b3"
      },
      "id": "4uYbFkAoQxZf",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.int64(284), np.int64(17))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = train_ds.reduce(tf.constant(0), lambda x, _: x + 1).numpy()\n",
        "train_ds = train_ds.cache()\n",
        "train_ds = train_ds.apply(tf.data.experimental.assert_cardinality(count))"
      ],
      "metadata": {
        "id": "eC32s-jSXVJz"
      },
      "id": "eC32s-jSXVJz",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.data.experimental.cardinality(train_ds).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-HgQnFc9Y4L",
        "outputId": "a62e9c25-3016-4bd2-88f1-a48f1757b596"
      },
      "id": "0-HgQnFc9Y4L",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(1229566)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = (\n",
        "    train_ds\n",
        "    .map(\n",
        "        lambda x, y: ((x, y), tf.constant(1)),\n",
        "        num_parallel_calls=tf.data.AUTOTUNE,\n",
        "    )\n",
        ")\n",
        "print(train_ds.element_spec)\n",
        "next(train_ds.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwxOCxw7YmyW",
        "outputId": "314637a5-abe4-4828-badd-c0e0f6ec5f08"
      },
      "id": "IwxOCxw7YmyW",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None)), TensorSpec(shape=(), dtype=tf.int32, name=None))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((np.int64(284), np.int64(17)), np.int32(1))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Embedding, Dot, Activation, Flatten\n",
        "\n",
        "embedding_dims = [45, 312, 752]\n",
        "window_sizes   = [2, 4]\n",
        "histories      = {}\n",
        "\n",
        "for w in window_sizes:\n",
        "    for ed in embedding_dims:\n",
        "        print(f\"{w=}, {ed=}\")\n",
        "        train_ds = tf.data.Dataset.from_tensor_slices(train_df[\"text\"])\n",
        "\n",
        "        train_ds = (\n",
        "            train_ds\n",
        "            .map(\n",
        "                lambda x: vectorize_layer(x),\n",
        "                num_parallel_calls=tf.data.AUTOTUNE,\n",
        "            )\n",
        "            .flat_map(\n",
        "                lambda x: generate_skipgram_pairs(x, window_size=w),\n",
        "            )\n",
        "        )\n",
        "\n",
        "        count = train_ds.reduce(tf.constant(0), lambda x, _: x + 1).numpy()\n",
        "        train_ds = train_ds.cache()\n",
        "        train_ds = train_ds.apply(tf.data.experimental.assert_cardinality(count))\n",
        "\n",
        "        train_ds = (\n",
        "            train_ds\n",
        "            .map(\n",
        "                lambda x, y: ((x, y), tf.constant(1)),\n",
        "                num_parallel_calls=tf.data.AUTOTUNE,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Index-based input (scalar integer)\n",
        "        input_target = Input(shape=(), dtype=tf.int32)\n",
        "        input_context = Input(shape=(), dtype=tf.int32)\n",
        "\n",
        "        # Shared embedding layer\n",
        "        embedding_layer = Embedding(input_dim=vocab_size, output_dim=ed)\n",
        "\n",
        "        target_embedding = embedding_layer(input_target)   # shape: (ed,)\n",
        "        context_embedding = embedding_layer(input_context) # shape: (ed,)\n",
        "\n",
        "        # If shape issues arise, flatten the embedding\n",
        "        target_embedding = Flatten()(target_embedding)\n",
        "        context_embedding = Flatten()(context_embedding)\n",
        "\n",
        "        # Dot product of embeddings\n",
        "        dot_product = Dot(axes=-1)([target_embedding, context_embedding])\n",
        "\n",
        "        # Sigmoid output for skipgram-style binary prediction\n",
        "        output = Activation('sigmoid')(dot_product)\n",
        "\n",
        "        model = Model(inputs=[input_target, input_context], outputs=output)\n",
        "        model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "        history = model.fit(train_ds.batch(1024).prefetch(tf.data.AUTOTUNE), epochs=3)\n",
        "\n",
        "        histories[(w, ed)] = history\n",
        "\n",
        "list(histories.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoISc-dCR32e",
        "outputId": "1a4c7c79-12b7-42f3-f918-79d66f8bfc85"
      },
      "id": "CoISc-dCR32e",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1201/1201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 43ms/step - loss: 0.1745\n",
            "Epoch 2/5\n",
            "\u001b[1m1201/1201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - loss: 0.0015\n",
            "Epoch 3/5\n",
            "\u001b[1m1201/1201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - loss: 3.4168e-04\n",
            "Epoch 4/5\n",
            "\u001b[1m1201/1201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - loss: 1.2311e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m1201/1201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - loss: 5.2829e-05\n",
            "Epoch 1/5\n",
            "\u001b[1m1201/1201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 52ms/step - loss: 0.1095\n",
            "Epoch 2/5\n",
            "\u001b[1m1201/1201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 29ms/step - loss: 2.7836e-04\n",
            "Epoch 3/5\n",
            "\u001b[1m1201/1201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 29ms/step - loss: 6.8068e-05\n",
            "Epoch 4/5\n",
            "\u001b[1m1201/1201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 29ms/step - loss: 2.5855e-05\n",
            "Epoch 5/5\n",
            "\u001b[1m1201/1201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 29ms/step - loss: 1.1732e-05\n",
            "Epoch 1/5\n",
            "\u001b[1m1201/1201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 62ms/step - loss: 0.0916\n",
            "Epoch 2/5\n",
            "\u001b[1m1201/1201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 47ms/step - loss: 1.6051e-04\n",
            "Epoch 3/5\n",
            "\u001b[1m1201/1201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 46ms/step - loss: 4.1208e-05\n",
            "Epoch 4/5\n",
            "\u001b[1m1201/1201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 47ms/step - loss: 1.6166e-05\n",
            "Epoch 5/5\n",
            "\u001b[1m1201/1201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 47ms/step - loss: 7.5647e-06\n",
            "Epoch 1/5\n",
            "\u001b[1m2194/2194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 31ms/step - loss: 0.1176\n",
            "Epoch 2/5\n",
            "\u001b[1m2194/2194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 17ms/step - loss: 4.3401e-04\n",
            "Epoch 3/5\n",
            "\u001b[1m2194/2194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - loss: 7.4086e-05\n",
            "Epoch 4/5\n",
            "\u001b[1m2194/2194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 17ms/step - loss: 1.8721e-05\n",
            "Epoch 5/5\n",
            "\u001b[1m2194/2194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - loss: 5.6482e-06\n",
            "Epoch 1/5\n",
            "\u001b[1m2194/2194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 39ms/step - loss: 0.0730\n",
            "Epoch 2/5\n",
            "\u001b[1m2194/2194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 28ms/step - loss: 7.7489e-05\n",
            "Epoch 3/5\n",
            "\u001b[1m2194/2194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 28ms/step - loss: 1.4709e-05\n",
            "Epoch 4/5\n",
            "\u001b[1m2194/2194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 29ms/step - loss: 4.2634e-06\n",
            "Epoch 5/5\n",
            "\u001b[1m2194/2194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 29ms/step - loss: 1.5980e-06\n",
            "Epoch 1/5\n",
            "\u001b[1m2194/2194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 55ms/step - loss: 0.0605\n",
            "Epoch 2/5\n",
            "\u001b[1m2194/2194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 47ms/step - loss: 4.7413e-05\n",
            "Epoch 3/5\n",
            "\u001b[1m2194/2194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 47ms/step - loss: 9.5293e-06\n",
            "Epoch 4/5\n",
            "\u001b[1m2194/2194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 46ms/step - loss: 2.9409e-06\n",
            "Epoch 5/5\n",
            "\u001b[1m2194/2194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 47ms/step - loss: 1.1920e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(2, 45), (2, 312), (2, 752), (4, 45), (4, 312), (4, 752)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = embedding_layer.get_weights()[0]\n",
        "\n",
        "print(embeddings.shape)"
      ],
      "metadata": {
        "id": "Ibi-GFZhbPrc",
        "outputId": "5d2934a9-6dcf-4169-91bc-cd019f28b3b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Ibi-GFZhbPrc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8157, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: given vectorize_layer how to obtain the index for the word \"what\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Get the vocabulary from the vectorize_layer\n",
        "vocabulary = vectorize_layer.get_vocabulary()\n",
        "\n",
        "# Find the index of the word \"what\"\n",
        "try:\n",
        "    what_index = vocabulary.index(\"what\")\n",
        "    print(f\"The index of 'what' in the vocabulary is: {what_index}\")\n",
        "except ValueError:\n",
        "    print(\"'what' is not found in the vocabulary.\")\n"
      ],
      "metadata": {
        "id": "9eKQn7NKbd5J",
        "outputId": "32d192b5-81cc-4bc0-8647-c7aeb0d5e58b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9eKQn7NKbd5J",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The index of 'what' in the vocabulary is: 52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings[what_index].shape"
      ],
      "metadata": {
        "id": "uDOf3fuJb0zr",
        "outputId": "b60a33b2-acb7-4bed-df91-d31d371f2a76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "uDOf3fuJb0zr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128,)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_ds.element_spec)\n",
        "next(train_ds.as_numpy_iterator())"
      ],
      "metadata": {
        "id": "G80B_OCWPSYX",
        "outputId": "fe0345dc-ed6c-4830-e4de-7f535afbad75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "G80B_OCWPSYX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((TensorSpec(shape=(8157,), dtype=tf.float32, name=None), TensorSpec(shape=(8157,), dtype=tf.float32, name=None)), TensorSpec(shape=(), dtype=tf.float32, name=None))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([0., 0., 1., ..., 0., 0., 0.], dtype=float32),\n",
              "  array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)),\n",
              " np.float32(1.0))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_train_ds = tf.data.Dataset.from_tensor_slices((vectorized_train, df_train[\"sentiment\"].values))\n",
        "\n",
        "print(classifier_train_ds.element_spec)\n",
        "next(classifier_train_ds.as_numpy_iterator())"
      ],
      "metadata": {
        "id": "HS-tFMUvPYBb",
        "outputId": "ccdd09c4-ab95-41b5-d741-5620701a813d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "HS-tFMUvPYBb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(TensorSpec(shape=(33,), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  293,    17, 15185,    69,     2,   120,    47,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0]),\n",
              " b'neutral')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = tf.keras.layers.Embedding(\n",
        "    input_dim=embeddings.shape[0],\n",
        "    output_dim=embeddings.shape[1],\n",
        "    weights=[embeddings],\n",
        "    trainable=False\n",
        ")\n",
        "\n",
        "def embed_and_flatten(indices, label):\n",
        "    embedded = embedding_layer(indices)        # shape: (seq_len, embed_dim)\n",
        "    flat = tf.reshape(embedded, [-1])          # shape: (seq_len * embed_dim,)\n",
        "    return flat, label"
      ],
      "metadata": {
        "id": "8kin8-5YRikR"
      },
      "id": "8kin8-5YRikR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_train_ds = classifier_train_ds.map(embed_and_flatten)\n",
        "print(classifier_train_ds.element_spec)\n",
        "next(classifier_train_ds.as_numpy_iterator())"
      ],
      "metadata": {
        "id": "fQulJta9Qf4m",
        "outputId": "45e3f88f-36ec-459d-db4d-7994e18b27b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "fQulJta9Qf4m",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(TensorSpec(shape=(4224,), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.17132318, -0.15126888, -0.17530611, ...,  0.4272256 ,\n",
              "        -0.41871053, -0.40135565], dtype=float32),\n",
              " b'neutral')"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a lookup table to convert string → integer\n",
        "label_lookup = tf.keras.layers.StringLookup(\n",
        "    vocabulary=df_train[\"sentiment\"].unique().tolist(),\n",
        "    num_oov_indices=0,\n",
        ")\n",
        "\n",
        "# Optional: one-hot encode\n",
        "num_classes = label_lookup.vocabulary_size()\n",
        "\n",
        "classifier_train_ds = classifier_train_ds.map(lambda x, y: (x, tf.one_hot(label_lookup(y), depth=num_classes)))\n",
        "\n",
        "print(classifier_train_ds.element_spec)\n",
        "next(classifier_train_ds.as_numpy_iterator())"
      ],
      "metadata": {
        "id": "VC1oGoZeYIKe",
        "outputId": "5e75026e-f419-4367-8f46-aae31c8ac786",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "VC1oGoZeYIKe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(TensorSpec(shape=(4224,), dtype=tf.float32, name=None), TensorSpec(shape=(3,), dtype=tf.float32, name=None))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.17132318, -0.15126888, -0.17530611, ...,  0.4272256 ,\n",
              "        -0.41871053, -0.40135565], dtype=float32),\n",
              " array([1., 0., 0.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_train_ds = classifier_train_ds.batch(128)"
      ],
      "metadata": {
        "id": "-f4ljpZPUwEC"
      },
      "id": "-f4ljpZPUwEC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')  # 3-class classification\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(classifier_train_ds, epochs=3)\n"
      ],
      "metadata": {
        "id": "uQ2vXFPkUGM0",
        "outputId": "9cc79eee-6daf-40cc-cf71-630e554f5f24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "uQ2vXFPkUGM0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.3925 - loss: 0.6410\n",
            "Epoch 2/3\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4302 - loss: 0.6215\n",
            "Epoch 3/3\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4364 - loss: 0.6138\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fb6dc72b1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}